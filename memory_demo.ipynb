{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "# Set up the state\n",
    "from langgraph.graph import MessagesState, START\n",
    "\n",
    "# Set up the tool\n",
    "# We will have one real tool - a search tool\n",
    "# We'll also have one \"fake\" tool - a \"ask_human\" tool\n",
    "# Here we define any ACTUAL tools\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# Set up the model\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import my_db_specifics as my_db_specifics\n",
    "from langchain_community.vectorstores import LanceDB\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "# Set up memory\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Build the graph\n",
    "\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "import duckdb\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "import sqlite3\n",
    "\n",
    "import utils.my_langchain_tools as my_langchain_tools\n",
    "import graph_definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as stream:\n",
    "    try:\n",
    "        PARAM = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = PARAM['openai_api']\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=PARAM['vector_embedding_model']\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph_definition.app.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'What is the MOA of Nicotinamide? Use the graph query.',\n",
       "  'query': \"FROM GRAPH_TABLE (drug_graph\\n    MATCH\\n        (d:Drug WHERE LOWER(d.name) = LOWER('Nicotinamide'))-[h:HAS_MOA]->(m:MOA)\\n    COLUMNS (m.name AS moa_name)\\n    );\\n    \",\n",
       "  'tool_name': 'graph'},\n",
       " {'input': \"Which drugs can be used to treat Alzheimer's Disease? Only give me all results without limit.\",\n",
       "  'query': \"FROM GRAPH_TABLE (drug_graph\\n    MATCH\\n        (i:Drug)-[m:MAY_TREAT]->(c:Disorder WHERE LOWER(c.name) = LOWER('Alzheimer''s Disease'))\\n    COLUMNS (i.name AS drug_name)\\n    );\\n                    \",\n",
       "  'tool_name': 'graph'},\n",
       " {'input': \"What is the mechanism of action of drugs that can treat Alzheimer's Disease? Give me 5 drugs and their MOA.\",\n",
       "  'query': \"FROM GRAPH_TABLE (drug_graph\\n    MATCH\\n        (mo:MOA)<-[h:HAS_MOA]-(i:Drug)-[m:MAY_TREAT]->(c:Disorder WHERE LOWER(c.name) = LOWER('Alzheimer''s Disease'))\\n    COLUMNS (i.name AS drug_name, mo.name AS moa_name)\\n    );\\n            \",\n",
       "  'tool_name': 'graph'},\n",
       " {'input': \"What disorders can drugs with the 'GABA B receptor interactions' MOA treat? Give me 3 drugs and their targeting disorders.\",\n",
       "  'query': \"FROM GRAPH_TABLE (drug_graph\\n    MATCH\\n        (mo:MOA WHERE LOWER(mo.name) = LOWER('GABA B receptor interactions'))<-[h:HAS_MOA]-(i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\n    COLUMNS (i.name AS drug_name, c.name AS disorder_name)\\n    );\\n            \",\n",
       "  'tool_name': 'graph'},\n",
       " {'input': 'What diseases can etoposide treat? Only give me all results without limit.',\n",
       "  'query': \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('etoposide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    );\\n                    \",\n",
       "  'tool_name': 'graph'},\n",
       " {'input': 'What is Fascioliasis?',\n",
       "  'query': \"FROM GRAPH_TABLE (drug_graph\\n    MATCH\\n        (c:Disorder WHERE LOWER(c.name) = LOWER('Fascioliasis'))\\n    COLUMNS (c.definition AS disorder_definition)\\n    );              \\n                    \",\n",
       "  'tool_name': 'graph'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_description = my_db_specifics.graph_database_prompt\n",
    "examples = my_db_specifics.graph_examples\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "        examples,\n",
    "        OpenAIEmbeddings(),\n",
    "        LanceDB,\n",
    "        k=2,\n",
    "        input_keys=[\"input\"],\n",
    "        #example_keys=[\"\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'input': 'What diseases can etoposide treat? Only give me all results without limit.',\n",
       "  'query': \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('etoposide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    );\\n                    \",\n",
       "  'tool_name': 'graph'},\n",
       " {'input': \"What disorders can drugs with the 'GABA B receptor interactions' MOA treat? Give me 3 drugs and their targeting disorders.\",\n",
       "  'query': \"FROM GRAPH_TABLE (drug_graph\\n    MATCH\\n        (mo:MOA WHERE LOWER(mo.name) = LOWER('GABA B receptor interactions'))<-[h:HAS_MOA]-(i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\n    COLUMNS (i.name AS drug_name, c.name AS disorder_name)\\n    );\\n            \",\n",
       "  'tool_name': 'graph'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector.select_examples({\"input\": \"What diseases can hydroflumethiazide treat?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 1\n",
      "Before response\n",
      "---select_intent---\n",
      "response:  content='' additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0' tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}] usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "---route_message---\n",
      " message: [HumanMessage(content='What diseases can hydroflumethiazide treat?', additional_kwargs={}, response_metadata={}, id='4a5b31cb-5ab5-4f81-a04e-43bb334139ac', tool_choice='graph'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "len(message.tool_calls) =  1\n",
      "---route_message---\n",
      " tool_call: {'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}\n",
      "***********select_query_tool\n",
      "len: 2\n",
      "---select_query_tool---\n",
      "I captured the tool_call_id call_YTIZsoSW3e0LyVmmJpGr25DV\n",
      "len: 3\n",
      "---call_tool_to_generate_query---\n",
      "---call_tool_to_generate_query---\n",
      "obj_tools: [StructuredTool(name='graph', description='Use the graph query language route to get the answer from the database. Only suitable for questions that involve the interrelationship between the Drugs, Disorders, and MOA tables. top_k is the number of results to return.', args_schema=<class 'langchain_core.utils.pydantic.graph'>, func=<function graph at 0x10af796c0>)]\n",
      "existing_memories None\n",
      "++++++++---In agent\n",
      "messages: [HumanMessage(content='What diseases can hydroflumethiazide treat?', additional_kwargs={}, response_metadata={}, id='4a5b31cb-5ab5-4f81-a04e-43bb334139ac', tool_choice='graph'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', tool_call_id='call_YTIZsoSW3e0LyVmmJpGr25DV')]\n",
      "++++++++---last_msg ['What diseases can hydroflumethiazide treat?']\n",
      "++++++++---In agent\n",
      "system_msg [SystemMessage(content=\"You are a helpful assistant tasked with performing RAG with a drug-trial DuckDB as backend. \\n                            Capture both the question and the amount of results 'top_k' that the user want to see. If the user does not specify the amount, set top_k = 50.\\n                            Only one query for one question. Do not break the question into multiple queries.\\n                            If the user has defined some concepts or terms, use them in your query faithfully to personalize your responses.\\n                            Here is the memory (it may be empty): \\n\", additional_kwargs={}, response_metadata={}), 'What diseases can hydroflumethiazide treat?']\n",
      "++++++++---In agent, agent_response content='' additional_kwargs={'tool_calls': [{'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'function': {'arguments': '{\"question\":\"What diseases can hydroflumethiazide treat?\",\"top_k\":50}', 'name': 'graph'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 205, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-e59d835d-8d04-43f2-9377-6ed9a0bde163-0' tool_calls=[{'name': 'graph', 'args': {'question': 'What diseases can hydroflumethiazide treat?', 'top_k': 50}, 'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'type': 'tool_call'}] usage_metadata={'input_tokens': 205, 'output_tokens': 28, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "len: 4\n",
      "++++++++++++++++question What diseases can hydroflumethiazide treat? top_k 50\n",
      "before examples\n",
      "before example_selector\n",
      "before example_prompt\n",
      "after example_prompt\n",
      "len: 5\n",
      "content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\" name='graph' id='d2d3b37c-ce8f-4f4f-b04b-250b43344e96' tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'\n",
      "---execute_query_and_answer---\n",
      "question What diseases can hydroflumethiazide treat?\n",
      "query FROM GRAPH_TABLE (drug_graph  \n",
      "    MATCH  \n",
      "        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \n",
      "    COLUMNS (c.name AS disorder_name)  \n",
      "    )\n",
      " LIMIT 50;\n",
      "m human content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\" additional_kwargs={} response_metadata={} name='graph' id='fff233cb-da4d-4c72-b376-6042bca9d72c' tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'\n",
      "m tool content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\" name='graph' id='d2d3b37c-ce8f-4f4f-b04b-250b43344e96' tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'\n",
      "return tool_call_id call_aWDuailOR4PHi3r1ad1EAMBK\n",
      "Hydroflumethiazide can treat the following diseases:\n",
      "\n",
      "1. Hypertensive disease\n",
      "2. Glomerulonephritis\n",
      "3. Heart failure\n",
      "4. Edema\n",
      "5. Kidney Failure\n",
      "6. Nephrotic Syndrome\n",
      "7. Liver Cirrhosis\n",
      "\n",
      "Alternatively, here is the information presented in a table format:\n",
      "\n",
      "| Disease                |\n",
      "|------------------------|\n",
      "| Hypertensive disease    |\n",
      "| Glomerulonephritis     |\n",
      "| Heart failure           |\n",
      "| Edema                  |\n",
      "| Kidney Failure          |\n",
      "| Nephrotic Syndrome      |\n",
      "| Liver Cirrhosis        |\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"sixing\"}}\n",
    "\n",
    "input_message = HumanMessage(\n",
    "    content=\"\"\"What diseases can hydroflumethiazide treat?\"\"\", tool_choice=\"graph\"\n",
    "    #content=\"\"\"Calculate the amount of trials sponsored by each of \"the Three small guys\".\"\"\", tool_choice=\"sql\"\n",
    ")\n",
    "\n",
    "for event in graph_definition.app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    print (\"len:\", len(event[\"messages\"]))\n",
    "\n",
    "print (graph_definition.app.get_state(config).values[\"messages\"][-1])\n",
    "\n",
    "tool_call_id = graph_definition.app.get_state(config).values[\"messages\"][-1].tool_call_id\n",
    "tool_name = graph_definition.app.get_state(config).values[\"messages\"][-1].name\n",
    "tool_content = graph_definition.app.get_state(config).values[\"messages\"][-1].content\n",
    "\n",
    "# We now create the tool call with the id and the response we want\n",
    "tool_message = [\n",
    "    {\n",
    "     \"tool_call_id\": tool_call_id, \n",
    "     \"name\": tool_name, \n",
    "     #\"type\": \"tool\",\n",
    "     \"type\": \"human\",\n",
    "        \"content\": tool_content}\n",
    "]\n",
    "\n",
    "# # This is equivalent to the below, either one works\n",
    "# from langchain_core.messages import ToolMessage\n",
    "# tool_message = [ToolMessage(tool_call_id=tool_call_id, content=\"san francisco\")]\n",
    "\n",
    "# We now update the state\n",
    "# Notice that we are also specifying `as_node=\"ask_human\"`\n",
    "# This will apply this update as this node,\n",
    "# which will make it so that afterwards it continues as normal\n",
    "graph_definition.app.update_state(config, {\"messages\": tool_message}, as_node=\"human_feedback\")\n",
    "events = list(graph_definition.app.stream(None, config, stream_mode=\"values\"))\n",
    "last_event = events[-1]\n",
    "print (last_event[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 8\n",
      "Before response\n",
      "---select_intent---\n",
      "response:  content='' additional_kwargs={'tool_calls': [{'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 632, 'total_tokens': 651, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-e2d2c45b-b39a-4099-99d8-60453bcb4698-0' tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'type': 'tool_call'}] usage_metadata={'input_tokens': 632, 'output_tokens': 19, 'total_tokens': 651, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "---route_message---\n",
      " message: [HumanMessage(content='What diseases can hydroflumethiazide treat?', additional_kwargs={}, response_metadata={}, id='4a5b31cb-5ab5-4f81-a04e-43bb334139ac', tool_choice='graph'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='9e4e6b47-7abc-44f2-aa9e-31e0f9478587', tool_call_id='call_YTIZsoSW3e0LyVmmJpGr25DV'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'function': {'arguments': '{\"question\":\"What diseases can hydroflumethiazide treat?\",\"top_k\":50}', 'name': 'graph'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 205, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e59d835d-8d04-43f2-9377-6ed9a0bde163-0', tool_calls=[{'name': 'graph', 'args': {'question': 'What diseases can hydroflumethiazide treat?', 'top_k': 50}, 'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 205, 'output_tokens': 28, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", name='graph', id='d2d3b37c-ce8f-4f4f-b04b-250b43344e96', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='graph', id='fff233cb-da4d-4c72-b376-6042bca9d72c', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), AIMessage(content='Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', additional_kwargs={'question': 'What diseases can hydroflumethiazide treat?', 'query': \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'execute_result': [['Hypertensive disease'], ['Glomerulonephritis'], ['Heart failure'], ['Edema'], ['Kidney Failure'], ['Nephrotic Syndrome'], ['Liver Cirrhosis']]}, response_metadata={}, id='a5be0b97-ad85-4671-a199-71d2bad0e031', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content='Show 5 trials that tested drugs against the top 7 liver-related disorders', additional_kwargs={}, response_metadata={}, id='309995b9-7d79-441d-97be-70248bbb8522', tool_choice='mimicking'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 632, 'total_tokens': 651, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e2d2c45b-b39a-4099-99d8-60453bcb4698-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 632, 'output_tokens': 19, 'total_tokens': 651, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "len(message.tool_calls) =  1\n",
      "---route_message---\n",
      " tool_call: {'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'type': 'tool_call'}\n",
      "***********select_query_tool\n",
      "len: 9\n",
      "---select_query_tool---\n",
      "I captured the tool_call_id call_4mTVMhHDl0QemMmmHuBRhZTP\n",
      "len: 10\n",
      "---call_tool_to_generate_query---\n",
      "---call_tool_to_generate_query---\n",
      "obj_tools: [StructuredTool(name='mimicking', description='When you think the question is unlikely to be answer by a single simple query tool, \\nor the question may likely require a complex combination of sql, vector, graph, and full-text search tools,\\nor it may require to join several tables, use this tool to generate those complex queries by closely mimicing the examples.', args_schema=<class 'langchain_core.utils.pydantic.mimicking'>, func=<function mimicking at 0x10af79580>)]\n",
      "existing_memories None\n",
      "++++++++---In agent\n",
      "messages: [HumanMessage(content='What diseases can hydroflumethiazide treat?', additional_kwargs={}, response_metadata={}, id='4a5b31cb-5ab5-4f81-a04e-43bb334139ac', tool_choice='graph'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='9e4e6b47-7abc-44f2-aa9e-31e0f9478587', tool_call_id='call_YTIZsoSW3e0LyVmmJpGr25DV'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'function': {'arguments': '{\"question\":\"What diseases can hydroflumethiazide treat?\",\"top_k\":50}', 'name': 'graph'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 205, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e59d835d-8d04-43f2-9377-6ed9a0bde163-0', tool_calls=[{'name': 'graph', 'args': {'question': 'What diseases can hydroflumethiazide treat?', 'top_k': 50}, 'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 205, 'output_tokens': 28, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", name='graph', id='d2d3b37c-ce8f-4f4f-b04b-250b43344e96', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='graph', id='fff233cb-da4d-4c72-b376-6042bca9d72c', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), AIMessage(content='Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', additional_kwargs={'question': 'What diseases can hydroflumethiazide treat?', 'query': \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'execute_result': [['Hypertensive disease'], ['Glomerulonephritis'], ['Heart failure'], ['Edema'], ['Kidney Failure'], ['Nephrotic Syndrome'], ['Liver Cirrhosis']]}, response_metadata={}, id='a5be0b97-ad85-4671-a199-71d2bad0e031', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content='Show 5 trials that tested drugs against the top 7 liver-related disorders', additional_kwargs={}, response_metadata={}, id='309995b9-7d79-441d-97be-70248bbb8522', tool_choice='mimicking'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 632, 'total_tokens': 651, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e2d2c45b-b39a-4099-99d8-60453bcb4698-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 632, 'output_tokens': 19, 'total_tokens': 651, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', tool_call_id='call_4mTVMhHDl0QemMmmHuBRhZTP')]\n",
      "++++++++---last_msg ['What diseases can hydroflumethiazide treat?', \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', 'Show 5 trials that tested drugs against the top 7 liver-related disorders']\n",
      "++++++++---In agent\n",
      "system_msg [SystemMessage(content=\"You are a helpful assistant tasked with performing RAG with a drug-trial DuckDB as backend. \\n                            Capture both the question and the amount of results 'top_k' that the user want to see. If the user does not specify the amount, set top_k = 50.\\n                            Only one query for one question. Do not break the question into multiple queries.\\n                            If the user has defined some concepts or terms, use them in your query faithfully to personalize your responses.\\n                            Here is the memory (it may be empty): \\n\", additional_kwargs={}, response_metadata={}), 'What diseases can hydroflumethiazide treat?', \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', 'Show 5 trials that tested drugs against the top 7 liver-related disorders']\n",
      "++++++++---In agent, agent_response content='' additional_kwargs={'tool_calls': [{'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'function': {'arguments': '{\"question\":\"Show 5 trials that tested drugs against the top 7 liver-related disorders\",\"top_k\":5}', 'name': 'mimicking'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 441, 'total_tokens': 475, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-db90e46b-c064-4c39-ac48-9b5d40f60958-0' tool_calls=[{'name': 'mimicking', 'args': {'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'top_k': 5}, 'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'type': 'tool_call'}] usage_metadata={'input_tokens': 441, 'output_tokens': 34, 'total_tokens': 475, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "len: 11\n",
      "in mimicking\n",
      "examples [\n",
      "  {\n",
      "    \"input\": \"Give me 3 liver-related disorders\",\n",
      "    \"query\": \"SELECT name, definition\\n        FROM Disorder\\n        ORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\n        LIMIT 3;\",\n",
      "    \"tool_name\": \"mimicking\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"Show 5 trials and their drugs. At least one of the drugs must be used to treat against the Non-small cell lung carcinoma?\",\n",
      "    \"query\": \"SELECT Trials.StudyTitle as StudyTitle, drug_for_disease.drug_name\\n         FROM Trials,\\n         GRAPH_TABLE(\\n        drug_graph\\n         MATCH\\n         (i:Drug)-[m:MAY_TREAT]->(c:Disorder WHERE LOWER(c.name) = LOWER('Non-small cell lung carcinoma'))\\n         COLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name)\\n        )  drug_for_disease\\n         WHERE list_contains(Trials.drug_cui, drug_for_disease.drug_cui)\\n        LIMIT 5;\",\n",
      "    \"tool_name\": \"mimicking\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"Show 3 trials that tested drugs against the top 10 joint-related disorders\",\n",
      "    \"query\": \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\n FROM Trials,\\n (SELECT disorder_cui, name FROM Disorder\\n ORDER BY array_distance(definitionEmbedding, embeddings('joint-related disorders')::FLOAT[1536])\\n  LIMIT 10) target_disease,\\n GRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\n COLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name,c.disorder_cui AS disorder_cui))  drug_for_disorder\\n WHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\n LIMIT 3\",\n",
      "    \"tool_name\": \"mimicking\"\n",
      "  },\n",
      "  {\n",
      "    \"input\": \"Show 4 trials that tested drugs with the MOA of 'UGT1A9 Inhibitors'\",\n",
      "    \"query\": \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, drug_with_moa.drug_name FROM Trials,\\n      GRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:HAS_MOA]->(a:MOA WHERE a.name='UGT1A9 Inhibitors')\\n               COLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name)) drug_with_moa\\n WHERE list_contains(Trials.drug_cui, drug_with_moa.drug_cui) LIMIT 4\",\n",
      "    \"tool_name\": \"mimicking\"\n",
      "  }\n",
      "]\n",
      "before example_selector\n",
      "before example_prompt\n",
      "after example_prompt\n",
      "before generate_query\n",
      "query SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\n",
      "FROM Trials,\n",
      "(SELECT disorder_cui, name FROM Disorder\n",
      "ORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\n",
      "LIMIT 7) target_disease,\n",
      "GRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\n",
      "COLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\n",
      "WHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\n",
      "LIMIT 5;\n",
      "len: 12\n",
      "content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\" name='mimicking' id='754879b8-225b-4a3b-8cec-a690f679f044' tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'\n",
      "---execute_query_and_answer---\n",
      "question Show 5 trials that tested drugs against the top 7 liver-related disorders\n",
      "query SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\n",
      "FROM Trials,\n",
      "(SELECT disorder_cui, name FROM Disorder\n",
      "ORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\n",
      "LIMIT 7) target_disease,\n",
      "GRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\n",
      "COLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\n",
      "WHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\n",
      "LIMIT 5;\n",
      "m human content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\" additional_kwargs={} response_metadata={} name='mimicking' id='4d5ed412-2709-4106-9c1e-ff4a8b53cc45' tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'\n",
      "m tool content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\" name='mimicking' id='754879b8-225b-4a3b-8cec-a690f679f044' tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'\n",
      "return tool_call_id call_NQky5Kfynd5inJQEd9k0WKfX\n",
      "Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\n",
      "\n",
      "| Trial ID | Title                                                                                                            | Disorder     | Drug             |\n",
      "|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\n",
      "| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\n",
      "| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\n",
      "| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\n",
      "| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\n",
      "| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\n",
      "\n",
      "These trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"sixing\"}}\n",
    "\n",
    "input_message = HumanMessage(\n",
    "    content=\"\"\"Show 5 trials that tested drugs against the top 7 liver-related disorders\"\"\", tool_choice=\"mimicking\"\n",
    "    #content=\"\"\"Calculate the amount of trials sponsored by each of \"the Three small guys\".\"\"\", tool_choice=\"sql\"\n",
    ")\n",
    "\n",
    "for event in graph_definition.app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    print (\"len:\", len(event[\"messages\"]))\n",
    "\n",
    "print (graph_definition.app.get_state(config).values[\"messages\"][-1])\n",
    "\n",
    "tool_call_id = graph_definition.app.get_state(config).values[\"messages\"][-1].tool_call_id\n",
    "tool_name = graph_definition.app.get_state(config).values[\"messages\"][-1].name\n",
    "tool_content = graph_definition.app.get_state(config).values[\"messages\"][-1].content\n",
    "\n",
    "# We now create the tool call with the id and the response we want\n",
    "tool_message = [\n",
    "    {\n",
    "     \"tool_call_id\": tool_call_id, \n",
    "     \"name\": tool_name, \n",
    "     #\"type\": \"tool\",\n",
    "     \"type\": \"human\",\n",
    "        \"content\": tool_content}\n",
    "]\n",
    "\n",
    "# # This is equivalent to the below, either one works\n",
    "# from langchain_core.messages import ToolMessage\n",
    "# tool_message = [ToolMessage(tool_call_id=tool_call_id, content=\"san francisco\")]\n",
    "\n",
    "# We now update the state\n",
    "# Notice that we are also specifying `as_node=\"ask_human\"`\n",
    "# This will apply this update as this node,\n",
    "# which will make it so that afterwards it continues as normal\n",
    "graph_definition.app.update_state(config, {\"messages\": tool_message}, as_node=\"human_feedback\")\n",
    "events = list(graph_definition.app.stream(None, config, stream_mode=\"values\"))\n",
    "last_event = events[-1]\n",
    "print (last_event[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV\n",
      "Before response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 19:25:10.074 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-22 19:25:10.075 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2024-11-22 19:25:10.076 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---select_intent---\n",
      "response:  content='' additional_kwargs={'tool_calls': [{'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1418, 'total_tokens': 1437, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-65d48a4a-01aa-4455-acaf-42508150fa42-0' tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1418, 'output_tokens': 19, 'total_tokens': 1437, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "---route_message---\n",
      " message: [HumanMessage(content='What diseases can hydroflumethiazide treat?', additional_kwargs={}, response_metadata={}, id='4a5b31cb-5ab5-4f81-a04e-43bb334139ac', tool_choice='graph'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='9e4e6b47-7abc-44f2-aa9e-31e0f9478587', tool_call_id='call_YTIZsoSW3e0LyVmmJpGr25DV'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'function': {'arguments': '{\"question\":\"What diseases can hydroflumethiazide treat?\",\"top_k\":50}', 'name': 'graph'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 205, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e59d835d-8d04-43f2-9377-6ed9a0bde163-0', tool_calls=[{'name': 'graph', 'args': {'question': 'What diseases can hydroflumethiazide treat?', 'top_k': 50}, 'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 205, 'output_tokens': 28, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", name='graph', id='d2d3b37c-ce8f-4f4f-b04b-250b43344e96', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='graph', id='fff233cb-da4d-4c72-b376-6042bca9d72c', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), AIMessage(content='Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', additional_kwargs={'question': 'What diseases can hydroflumethiazide treat?', 'query': \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'execute_result': [['Hypertensive disease'], ['Glomerulonephritis'], ['Heart failure'], ['Edema'], ['Kidney Failure'], ['Nephrotic Syndrome'], ['Liver Cirrhosis']]}, response_metadata={}, id='a5be0b97-ad85-4671-a199-71d2bad0e031', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content='Show 5 trials that tested drugs against the top 7 liver-related disorders', additional_kwargs={}, response_metadata={}, id='309995b9-7d79-441d-97be-70248bbb8522', tool_choice='mimicking'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 632, 'total_tokens': 651, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e2d2c45b-b39a-4099-99d8-60453bcb4698-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 632, 'output_tokens': 19, 'total_tokens': 651, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='41e094bc-08a8-4401-af40-e2600224565c', tool_call_id='call_4mTVMhHDl0QemMmmHuBRhZTP'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'function': {'arguments': '{\"question\":\"Show 5 trials that tested drugs against the top 7 liver-related disorders\",\"top_k\":5}', 'name': 'mimicking'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 441, 'total_tokens': 475, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-db90e46b-c064-4c39-ac48-9b5d40f60958-0', tool_calls=[{'name': 'mimicking', 'args': {'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'top_k': 5}, 'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 441, 'output_tokens': 34, 'total_tokens': 475, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", name='mimicking', id='754879b8-225b-4a3b-8cec-a690f679f044', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", additional_kwargs={}, response_metadata={}, name='mimicking', id='4d5ed412-2709-4106-9c1e-ff4a8b53cc45', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), AIMessage(content='Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\\n\\n| Trial ID | Title                                                                                                            | Disorder     | Drug             |\\n|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\\n| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\\n| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\\n| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\\n| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\\n| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\\n\\nThese trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.', additional_kwargs={'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'query': \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", 'execute_result': [[20297, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran.', 'Fascioliasis', 'triclabendazole'], [20298, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile.', 'Fascioliasis', 'triclabendazole'], [20299, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba.', 'Fascioliasis', 'triclabendazole'], [20300, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia.', 'Fascioliasis', 'triclabendazole'], [20301, 'Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke).', 'Fascioliasis', 'triclabendazole']]}, response_metadata={}, id='dd184c63-e0ec-41aa-9398-8648ae918d83', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content='The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV', additional_kwargs={}, response_metadata={}, id='168c56b2-77e8-4b14-b21b-af03ef8135c0'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1418, 'total_tokens': 1437, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-65d48a4a-01aa-4455-acaf-42508150fa42-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1418, 'output_tokens': 19, 'total_tokens': 1437, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "len(message.tool_calls) =  1\n",
      "---route_message---\n",
      " tool_call: {'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'type': 'tool_call'}\n",
      "***********update_concept\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Choose_Direction (call_BbnYMzW6NWuYXHItZSSTlNqY)\n",
      " Call ID: call_BbnYMzW6NWuYXHItZSSTlNqY\n",
      "  Args:\n",
      "    action_type: update_concept\n",
      "---update_concept---\n",
      ",,,,,,,,,,,,,,,,,,,,,,,,update_concept---tool_calls))))))))))))\n",
      " [{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'type': 'tool_call'}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: memory\n",
      "\n",
      "updated concept\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"sixing\"}}\n",
    "\n",
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"\"\"The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV\"\"\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph_definition.app.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "We also define \"the Market leader\" company as GSK\n",
      "Before response\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 19:25:11.737 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-22 19:25:11.738 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---select_intent---\n",
      "response:  content='' additional_kwargs={'tool_calls': [{'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1464, 'total_tokens': 1483, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-6951dbc0-47d3-42b7-9009-84fe6f6c7a5b-0' tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1464, 'output_tokens': 19, 'total_tokens': 1483, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "---route_message---\n",
      " message: [HumanMessage(content='What diseases can hydroflumethiazide treat?', additional_kwargs={}, response_metadata={}, id='4a5b31cb-5ab5-4f81-a04e-43bb334139ac', tool_choice='graph'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='9e4e6b47-7abc-44f2-aa9e-31e0f9478587', tool_call_id='call_YTIZsoSW3e0LyVmmJpGr25DV'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'function': {'arguments': '{\"question\":\"What diseases can hydroflumethiazide treat?\",\"top_k\":50}', 'name': 'graph'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 205, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e59d835d-8d04-43f2-9377-6ed9a0bde163-0', tool_calls=[{'name': 'graph', 'args': {'question': 'What diseases can hydroflumethiazide treat?', 'top_k': 50}, 'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 205, 'output_tokens': 28, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", name='graph', id='d2d3b37c-ce8f-4f4f-b04b-250b43344e96', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='graph', id='fff233cb-da4d-4c72-b376-6042bca9d72c', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), AIMessage(content='Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', additional_kwargs={'question': 'What diseases can hydroflumethiazide treat?', 'query': \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'execute_result': [['Hypertensive disease'], ['Glomerulonephritis'], ['Heart failure'], ['Edema'], ['Kidney Failure'], ['Nephrotic Syndrome'], ['Liver Cirrhosis']]}, response_metadata={}, id='a5be0b97-ad85-4671-a199-71d2bad0e031', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content='Show 5 trials that tested drugs against the top 7 liver-related disorders', additional_kwargs={}, response_metadata={}, id='309995b9-7d79-441d-97be-70248bbb8522', tool_choice='mimicking'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 632, 'total_tokens': 651, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e2d2c45b-b39a-4099-99d8-60453bcb4698-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 632, 'output_tokens': 19, 'total_tokens': 651, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='41e094bc-08a8-4401-af40-e2600224565c', tool_call_id='call_4mTVMhHDl0QemMmmHuBRhZTP'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'function': {'arguments': '{\"question\":\"Show 5 trials that tested drugs against the top 7 liver-related disorders\",\"top_k\":5}', 'name': 'mimicking'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 441, 'total_tokens': 475, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-db90e46b-c064-4c39-ac48-9b5d40f60958-0', tool_calls=[{'name': 'mimicking', 'args': {'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'top_k': 5}, 'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 441, 'output_tokens': 34, 'total_tokens': 475, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", name='mimicking', id='754879b8-225b-4a3b-8cec-a690f679f044', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", additional_kwargs={}, response_metadata={}, name='mimicking', id='4d5ed412-2709-4106-9c1e-ff4a8b53cc45', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), AIMessage(content='Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\\n\\n| Trial ID | Title                                                                                                            | Disorder     | Drug             |\\n|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\\n| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\\n| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\\n| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\\n| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\\n| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\\n\\nThese trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.', additional_kwargs={'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'query': \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", 'execute_result': [[20297, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran.', 'Fascioliasis', 'triclabendazole'], [20298, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile.', 'Fascioliasis', 'triclabendazole'], [20299, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba.', 'Fascioliasis', 'triclabendazole'], [20300, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia.', 'Fascioliasis', 'triclabendazole'], [20301, 'Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke).', 'Fascioliasis', 'triclabendazole']]}, response_metadata={}, id='dd184c63-e0ec-41aa-9398-8648ae918d83', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content='The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV', additional_kwargs={}, response_metadata={}, id='168c56b2-77e8-4b14-b21b-af03ef8135c0'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1418, 'total_tokens': 1437, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-65d48a4a-01aa-4455-acaf-42508150fa42-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1418, 'output_tokens': 19, 'total_tokens': 1437, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='updated concept', name='memory', id='6cd4f9f8-8510-4314-b5a1-6d115e93ae7e', tool_call_id='call_BbnYMzW6NWuYXHItZSSTlNqY'), HumanMessage(content='We also define \"the Market leader\" company as GSK', additional_kwargs={}, response_metadata={}, id='722645df-bc28-4f5d-8a2b-dec008bc7363'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1464, 'total_tokens': 1483, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6951dbc0-47d3-42b7-9009-84fe6f6c7a5b-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1464, 'output_tokens': 19, 'total_tokens': 1483, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "len(message.tool_calls) =  1\n",
      "---route_message---\n",
      " tool_call: {'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'type': 'tool_call'}\n",
      "***********update_concept\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Choose_Direction (call_6C8SUAwzy1H8bR2dkG6hrUnB)\n",
      " Call ID: call_6C8SUAwzy1H8bR2dkG6hrUnB\n",
      "  Args:\n",
      "    action_type: update_concept\n",
      "---update_concept---\n",
      ",,,,,,,,,,,,,,,,,,,,,,,,update_concept---tool_calls))))))))))))\n",
      " [{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'type': 'tool_call'}]\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: memory\n",
      "\n",
      "updated concept\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"sixing\"}}\n",
    "\n",
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"\"\"We also define \"the Market leader\" company as GSK\"\"\")]\n",
    "#input_messages = [HumanMessage(content=\"\"\"'Four Horsemen' are cardiovascular disease, cancer, neurodegenerative disease, and foundational disease\"\"\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph_definition.app.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 21\n",
      "Before response\n",
      "---select_intent---\n",
      "response:  content='' additional_kwargs={'tool_calls': [{'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1512, 'total_tokens': 1531, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-91cdf93c-3fe6-460a-bcb0-faeaa1146b64-0' tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1512, 'output_tokens': 19, 'total_tokens': 1531, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "---route_message---\n",
      " message: [HumanMessage(content='What diseases can hydroflumethiazide treat?', additional_kwargs={}, response_metadata={}, id='4a5b31cb-5ab5-4f81-a04e-43bb334139ac', tool_choice='graph'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='9e4e6b47-7abc-44f2-aa9e-31e0f9478587', tool_call_id='call_YTIZsoSW3e0LyVmmJpGr25DV'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'function': {'arguments': '{\"question\":\"What diseases can hydroflumethiazide treat?\",\"top_k\":50}', 'name': 'graph'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 205, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e59d835d-8d04-43f2-9377-6ed9a0bde163-0', tool_calls=[{'name': 'graph', 'args': {'question': 'What diseases can hydroflumethiazide treat?', 'top_k': 50}, 'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 205, 'output_tokens': 28, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", name='graph', id='d2d3b37c-ce8f-4f4f-b04b-250b43344e96', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='graph', id='fff233cb-da4d-4c72-b376-6042bca9d72c', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), AIMessage(content='Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', additional_kwargs={'question': 'What diseases can hydroflumethiazide treat?', 'query': \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'execute_result': [['Hypertensive disease'], ['Glomerulonephritis'], ['Heart failure'], ['Edema'], ['Kidney Failure'], ['Nephrotic Syndrome'], ['Liver Cirrhosis']]}, response_metadata={}, id='a5be0b97-ad85-4671-a199-71d2bad0e031', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content='Show 5 trials that tested drugs against the top 7 liver-related disorders', additional_kwargs={}, response_metadata={}, id='309995b9-7d79-441d-97be-70248bbb8522', tool_choice='mimicking'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 632, 'total_tokens': 651, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e2d2c45b-b39a-4099-99d8-60453bcb4698-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 632, 'output_tokens': 19, 'total_tokens': 651, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='41e094bc-08a8-4401-af40-e2600224565c', tool_call_id='call_4mTVMhHDl0QemMmmHuBRhZTP'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'function': {'arguments': '{\"question\":\"Show 5 trials that tested drugs against the top 7 liver-related disorders\",\"top_k\":5}', 'name': 'mimicking'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 441, 'total_tokens': 475, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-db90e46b-c064-4c39-ac48-9b5d40f60958-0', tool_calls=[{'name': 'mimicking', 'args': {'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'top_k': 5}, 'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 441, 'output_tokens': 34, 'total_tokens': 475, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", name='mimicking', id='754879b8-225b-4a3b-8cec-a690f679f044', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", additional_kwargs={}, response_metadata={}, name='mimicking', id='4d5ed412-2709-4106-9c1e-ff4a8b53cc45', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), AIMessage(content='Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\\n\\n| Trial ID | Title                                                                                                            | Disorder     | Drug             |\\n|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\\n| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\\n| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\\n| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\\n| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\\n| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\\n\\nThese trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.', additional_kwargs={'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'query': \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", 'execute_result': [[20297, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran.', 'Fascioliasis', 'triclabendazole'], [20298, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile.', 'Fascioliasis', 'triclabendazole'], [20299, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba.', 'Fascioliasis', 'triclabendazole'], [20300, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia.', 'Fascioliasis', 'triclabendazole'], [20301, 'Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke).', 'Fascioliasis', 'triclabendazole']]}, response_metadata={}, id='dd184c63-e0ec-41aa-9398-8648ae918d83', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content='The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV', additional_kwargs={}, response_metadata={}, id='168c56b2-77e8-4b14-b21b-af03ef8135c0'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1418, 'total_tokens': 1437, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-65d48a4a-01aa-4455-acaf-42508150fa42-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1418, 'output_tokens': 19, 'total_tokens': 1437, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='updated concept', name='memory', id='6cd4f9f8-8510-4314-b5a1-6d115e93ae7e', tool_call_id='call_BbnYMzW6NWuYXHItZSSTlNqY'), HumanMessage(content='We also define \"the Market leader\" company as GSK', additional_kwargs={}, response_metadata={}, id='722645df-bc28-4f5d-8a2b-dec008bc7363'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1464, 'total_tokens': 1483, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6951dbc0-47d3-42b7-9009-84fe6f6c7a5b-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1464, 'output_tokens': 19, 'total_tokens': 1483, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='updated concept', name='memory', id='598bd5fe-57a7-4b40-a13b-ec9fb44fe684', tool_call_id='call_6C8SUAwzy1H8bR2dkG6hrUnB'), HumanMessage(content='Tabulate the amount of trials sponsored by \"the Three small guys\".', additional_kwargs={}, response_metadata={}, id='fbc12694-32e1-4e69-94c7-16d6448aa025', tool_choice='sql'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1512, 'total_tokens': 1531, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-91cdf93c-3fe6-460a-bcb0-faeaa1146b64-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1512, 'output_tokens': 19, 'total_tokens': 1531, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "len(message.tool_calls) =  1\n",
      "---route_message---\n",
      " tool_call: {'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'type': 'tool_call'}\n",
      "***********select_query_tool\n",
      "len: 22\n",
      "---select_query_tool---\n",
      "I captured the tool_call_id call_FixZDNScYgtmHjosgoJwOIyC\n",
      "len: 23\n",
      "---call_tool_to_generate_query---\n",
      "---call_tool_to_generate_query---\n",
      "obj_tools: [StructuredTool(name='sql', description='Use the SQL route to get the answer from the database. It can find data across all tables. Consider it as the default tool. top_k is the number of results to return.', args_schema=<class 'langchain_core.utils.pydantic.sql'>, func=<function sql at 0x10af79620>)]\n",
      "existing_memories [{'name': 'Three Small Guys', 'items': ['Astellas', 'Novartis', 'ViiV']}, {'name': 'the Market leader', 'items': ['GSK']}]\n",
      "++++++++---In agent\n",
      "messages: [HumanMessage(content='What diseases can hydroflumethiazide treat?', additional_kwargs={}, response_metadata={}, id='4a5b31cb-5ab5-4f81-a04e-43bb334139ac', tool_choice='graph'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='9e4e6b47-7abc-44f2-aa9e-31e0f9478587', tool_call_id='call_YTIZsoSW3e0LyVmmJpGr25DV'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'function': {'arguments': '{\"question\":\"What diseases can hydroflumethiazide treat?\",\"top_k\":50}', 'name': 'graph'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 205, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e59d835d-8d04-43f2-9377-6ed9a0bde163-0', tool_calls=[{'name': 'graph', 'args': {'question': 'What diseases can hydroflumethiazide treat?', 'top_k': 50}, 'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 205, 'output_tokens': 28, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", name='graph', id='d2d3b37c-ce8f-4f4f-b04b-250b43344e96', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='graph', id='fff233cb-da4d-4c72-b376-6042bca9d72c', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), AIMessage(content='Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', additional_kwargs={'question': 'What diseases can hydroflumethiazide treat?', 'query': \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'execute_result': [['Hypertensive disease'], ['Glomerulonephritis'], ['Heart failure'], ['Edema'], ['Kidney Failure'], ['Nephrotic Syndrome'], ['Liver Cirrhosis']]}, response_metadata={}, id='a5be0b97-ad85-4671-a199-71d2bad0e031', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content='Show 5 trials that tested drugs against the top 7 liver-related disorders', additional_kwargs={}, response_metadata={}, id='309995b9-7d79-441d-97be-70248bbb8522', tool_choice='mimicking'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 632, 'total_tokens': 651, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e2d2c45b-b39a-4099-99d8-60453bcb4698-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 632, 'output_tokens': 19, 'total_tokens': 651, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='41e094bc-08a8-4401-af40-e2600224565c', tool_call_id='call_4mTVMhHDl0QemMmmHuBRhZTP'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'function': {'arguments': '{\"question\":\"Show 5 trials that tested drugs against the top 7 liver-related disorders\",\"top_k\":5}', 'name': 'mimicking'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 441, 'total_tokens': 475, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-db90e46b-c064-4c39-ac48-9b5d40f60958-0', tool_calls=[{'name': 'mimicking', 'args': {'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'top_k': 5}, 'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 441, 'output_tokens': 34, 'total_tokens': 475, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", name='mimicking', id='754879b8-225b-4a3b-8cec-a690f679f044', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", additional_kwargs={}, response_metadata={}, name='mimicking', id='4d5ed412-2709-4106-9c1e-ff4a8b53cc45', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), AIMessage(content='Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\\n\\n| Trial ID | Title                                                                                                            | Disorder     | Drug             |\\n|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\\n| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\\n| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\\n| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\\n| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\\n| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\\n\\nThese trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.', additional_kwargs={'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'query': \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", 'execute_result': [[20297, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran.', 'Fascioliasis', 'triclabendazole'], [20298, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile.', 'Fascioliasis', 'triclabendazole'], [20299, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba.', 'Fascioliasis', 'triclabendazole'], [20300, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia.', 'Fascioliasis', 'triclabendazole'], [20301, 'Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke).', 'Fascioliasis', 'triclabendazole']]}, response_metadata={}, id='dd184c63-e0ec-41aa-9398-8648ae918d83', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content='The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV', additional_kwargs={}, response_metadata={}, id='168c56b2-77e8-4b14-b21b-af03ef8135c0'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1418, 'total_tokens': 1437, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-65d48a4a-01aa-4455-acaf-42508150fa42-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1418, 'output_tokens': 19, 'total_tokens': 1437, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='updated concept', name='memory', id='6cd4f9f8-8510-4314-b5a1-6d115e93ae7e', tool_call_id='call_BbnYMzW6NWuYXHItZSSTlNqY'), HumanMessage(content='We also define \"the Market leader\" company as GSK', additional_kwargs={}, response_metadata={}, id='722645df-bc28-4f5d-8a2b-dec008bc7363'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1464, 'total_tokens': 1483, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6951dbc0-47d3-42b7-9009-84fe6f6c7a5b-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1464, 'output_tokens': 19, 'total_tokens': 1483, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='updated concept', name='memory', id='598bd5fe-57a7-4b40-a13b-ec9fb44fe684', tool_call_id='call_6C8SUAwzy1H8bR2dkG6hrUnB'), HumanMessage(content='Tabulate the amount of trials sponsored by \"the Three small guys\".', additional_kwargs={}, response_metadata={}, id='fbc12694-32e1-4e69-94c7-16d6448aa025', tool_choice='sql'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1512, 'total_tokens': 1531, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-91cdf93c-3fe6-460a-bcb0-faeaa1146b64-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1512, 'output_tokens': 19, 'total_tokens': 1531, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', tool_call_id='call_FixZDNScYgtmHjosgoJwOIyC')]\n",
      "++++++++---last_msg ['What diseases can hydroflumethiazide treat?', \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', 'Show 5 trials that tested drugs against the top 7 liver-related disorders', \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", 'Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\\n\\n| Trial ID | Title                                                                                                            | Disorder     | Drug             |\\n|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\\n| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\\n| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\\n| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\\n| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\\n| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\\n\\nThese trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.', 'The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV', 'We also define \"the Market leader\" company as GSK', 'Tabulate the amount of trials sponsored by \"the Three small guys\".']\n",
      "++++++++---In agent\n",
      "system_msg [SystemMessage(content=\"You are a helpful assistant tasked with performing RAG with a drug-trial DuckDB as backend. \\n                            Capture both the question and the amount of results 'top_k' that the user want to see. If the user does not specify the amount, set top_k = 50.\\n                            Only one query for one question. Do not break the question into multiple queries.\\n                            If the user has defined some concepts or terms, use them in your query faithfully to personalize your responses.\\n                            Here is the memory (it may be empty): \\n Three Small Guys: ['Astellas', 'Novartis', 'ViiV']\\n the Market leader: ['GSK']\\n\", additional_kwargs={}, response_metadata={}), 'What diseases can hydroflumethiazide treat?', \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', 'Show 5 trials that tested drugs against the top 7 liver-related disorders', \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", 'Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\\n\\n| Trial ID | Title                                                                                                            | Disorder     | Drug             |\\n|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\\n| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\\n| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\\n| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\\n| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\\n| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\\n\\nThese trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.', 'The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV', 'We also define \"the Market leader\" company as GSK', 'Tabulate the amount of trials sponsored by \"the Three small guys\".']\n",
      "++++++++---In agent, agent_response content='' additional_kwargs={'tool_calls': [{'id': 'call_AldpqkdPBSnKknGTCVDWjS7c', 'function': {'arguments': '{\"question\":\"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN (\\'Astellas\\', \\'Novartis\\', \\'ViiV\\') GROUP BY Sponsor\",\"top_k\":50}', 'name': 'sql'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 1017, 'total_tokens': 1065, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-88cb5860-7e1d-4f10-821c-aaca16ec7bce-0' tool_calls=[{'name': 'sql', 'args': {'question': \"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') GROUP BY Sponsor\", 'top_k': 50}, 'id': 'call_AldpqkdPBSnKknGTCVDWjS7c', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1017, 'output_tokens': 48, 'total_tokens': 1065, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "len: 24\n",
      "==== sql ====\n",
      "sql question SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') GROUP BY Sponsor top_k 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: PostgreSQL format_type() returned NULL for column 'definitionEmbedding'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'drug_cui'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'drug_names'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'source_pk'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'source_fk'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'destination_pk'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'destination_fk'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'sub_labels'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:174: DuckDBEngineWarning: duckdb-engine doesn't yet support reflection on indices\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_query first=RunnableAssign(mapper={\n",
      "  input: RunnableLambda(...),\n",
      "  table_info: RunnableLambda(...)\n",
      "}) middle=[RunnableLambda(lambda x: {k: v for k, v in x.items() if k not in ('question', 'table_names_to_use')}), FewShotPromptTemplate(input_variables=['input', 'table_info'], input_types={}, partial_variables={'top_k': '5'}, example_selector=SemanticSimilarityExampleSelector(vectorstore=<langchain_community.vectorstores.lancedb.LanceDB object at 0x12819efd0>, k=5, example_keys=None, input_keys=['input'], vectorstore_kwargs=None), example_prompt=PromptTemplate(input_variables=['input', 'query'], input_types={}, partial_variables={}, template='User input: {input}\\nSQL query: {query}'), suffix='User input: {input}\\nSQL query: ', prefix=\"You are a DuckDB expert. Given an input question, create a syntactically correct DuckDB query to run. Ignore the {top_k} parameter for now.\\n        Here is the relevant table info: {table_info}\\n        - If the search term contains a single quote, it should be escaped with another single quote. For example, 'Alzheimer's Disease' should be 'Alzheimer''s Disease'.\\n        - Only return SQL Query not anything else like ```sql ... ```\\n        - Using NOT IN with NULL values\\n        - Using UNION when UNION ALL should have been used\\n        - Using BETWEEN for exclusive ranges\\n        - Data type mismatch in predicates\\n        - Using the correct number of arguments for functions\\n        - Casting to the correct data type\\n        - Using the proper columns for joins\\n        - Never write a LIMIT clause.\\n        - Make sure all parentheses are balanced.\\n        - Ends with a semicolon\\n        - Output the final SQL query only.\\n        Below are a number of examples of questions and their corresponding SQL queries.\"), RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10af73620>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10af77230>, root_client=<openai.OpenAI object at 0x10ad2bcb0>, root_async_client=<openai.AsyncOpenAI object at 0x10af73770>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'stop': ['\\nSQLResult:']}, config={}, config_factories=[]), StrOutputParser()] last=RunnableLambda(_strip)\n",
      "len: 25\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"sixing\"}}\n",
    "\n",
    "input_message = HumanMessage(\n",
    "    content=\"\"\"Tabulate the amount of trials sponsored by \"the Three small guys\".\"\"\", tool_choice=\"sql\"\n",
    "    #content=\"\"\"Calculate the amount of trials sponsored by each of \"the Three small guys\".\"\"\", tool_choice=\"sql\"\n",
    ")\n",
    "\n",
    "for event in graph_definition.app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    print (\"len:\", len(event[\"messages\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\" name='sql' id='706718d3-c92f-4c59-b654-0b56d1718e8f' tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'\n",
      "---execute_query_and_answer---\n",
      "question SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') GROUP BY Sponsor\n",
      "query SELECT Sponsor, COUNT(*) AS TrialCount \n",
      "FROM Trials \n",
      "WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \n",
      "GROUP BY Sponsor\n",
      " LIMIT 50;\n",
      "m human content=\"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\" additional_kwargs={} response_metadata={} name='sql' id='652020e6-838a-42a7-aa08-6cfc6eabfa4f' tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'\n",
      "m tool content=\"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\" name='sql' id='706718d3-c92f-4c59-b654-0b56d1718e8f' tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'\n",
      "return tool_call_id call_AldpqkdPBSnKknGTCVDWjS7c\n",
      "Here are the results formatted into sentences:\n",
      "\n",
      "- Astellas has conducted 101 trials.\n",
      "- Novartis has conducted 239 trials.\n",
      "- ViiV has conducted 76 trials.\n",
      "\n",
      "Alternatively, the results can be presented in a table format:\n",
      "\n",
      "| Sponsor   | TrialCount |\n",
      "|-----------|------------|\n",
      "| Astellas  | 101        |\n",
      "| Novartis  | 239        |\n",
      "| ViiV     | 76         |\n"
     ]
    }
   ],
   "source": [
    "print (graph_definition.app.get_state(config).values[\"messages\"][-1])\n",
    "\n",
    "tool_call_id = graph_definition.app.get_state(config).values[\"messages\"][-1].tool_call_id\n",
    "tool_name = graph_definition.app.get_state(config).values[\"messages\"][-1].name\n",
    "tool_content = graph_definition.app.get_state(config).values[\"messages\"][-1].content\n",
    "\n",
    "# We now create the tool call with the id and the response we want\n",
    "tool_message = [\n",
    "    {\n",
    "     \"tool_call_id\": tool_call_id, \n",
    "     \"name\": tool_name, \n",
    "     #\"type\": \"tool\",\n",
    "     \"type\": \"human\",\n",
    "        \"content\": tool_content}\n",
    "]\n",
    "\n",
    "# # This is equivalent to the below, either one works\n",
    "# from langchain_core.messages import ToolMessage\n",
    "# tool_message = [ToolMessage(tool_call_id=tool_call_id, content=\"san francisco\")]\n",
    "\n",
    "# We now update the state\n",
    "# Notice that we are also specifying `as_node=\"ask_human\"`\n",
    "# This will apply this update as this node,\n",
    "# which will make it so that afterwards it continues as normal\n",
    "graph_definition.app.update_state(config, {\"messages\": tool_message}, as_node=\"human_feedback\")\n",
    "events = list(graph_definition.app.stream(None, config, stream_mode=\"values\"))\n",
    "last_event = events[-1]\n",
    "print (last_event[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 28\n",
      "Before response\n",
      "---select_intent---\n",
      "response:  content='' additional_kwargs={'tool_calls': [{'id': 'call_XzJ41uh35e3DbUk1gtc6L9t1', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1790, 'total_tokens': 1809, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1408}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-c03e4533-dea4-4242-bd34-8efe2afcebba-0' tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_XzJ41uh35e3DbUk1gtc6L9t1', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1790, 'output_tokens': 19, 'total_tokens': 1809, 'input_token_details': {'audio': 0, 'cache_read': 1408}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "---route_message---\n",
      " message: [HumanMessage(content='What diseases can hydroflumethiazide treat?', additional_kwargs={}, response_metadata={}, id='4a5b31cb-5ab5-4f81-a04e-43bb334139ac', tool_choice='graph'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='9e4e6b47-7abc-44f2-aa9e-31e0f9478587', tool_call_id='call_YTIZsoSW3e0LyVmmJpGr25DV'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'function': {'arguments': '{\"question\":\"What diseases can hydroflumethiazide treat?\",\"top_k\":50}', 'name': 'graph'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 205, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e59d835d-8d04-43f2-9377-6ed9a0bde163-0', tool_calls=[{'name': 'graph', 'args': {'question': 'What diseases can hydroflumethiazide treat?', 'top_k': 50}, 'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 205, 'output_tokens': 28, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", name='graph', id='d2d3b37c-ce8f-4f4f-b04b-250b43344e96', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='graph', id='fff233cb-da4d-4c72-b376-6042bca9d72c', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), AIMessage(content='Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', additional_kwargs={'question': 'What diseases can hydroflumethiazide treat?', 'query': \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'execute_result': [['Hypertensive disease'], ['Glomerulonephritis'], ['Heart failure'], ['Edema'], ['Kidney Failure'], ['Nephrotic Syndrome'], ['Liver Cirrhosis']]}, response_metadata={}, id='a5be0b97-ad85-4671-a199-71d2bad0e031', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content='Show 5 trials that tested drugs against the top 7 liver-related disorders', additional_kwargs={}, response_metadata={}, id='309995b9-7d79-441d-97be-70248bbb8522', tool_choice='mimicking'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 632, 'total_tokens': 651, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e2d2c45b-b39a-4099-99d8-60453bcb4698-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 632, 'output_tokens': 19, 'total_tokens': 651, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='41e094bc-08a8-4401-af40-e2600224565c', tool_call_id='call_4mTVMhHDl0QemMmmHuBRhZTP'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'function': {'arguments': '{\"question\":\"Show 5 trials that tested drugs against the top 7 liver-related disorders\",\"top_k\":5}', 'name': 'mimicking'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 441, 'total_tokens': 475, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-db90e46b-c064-4c39-ac48-9b5d40f60958-0', tool_calls=[{'name': 'mimicking', 'args': {'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'top_k': 5}, 'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 441, 'output_tokens': 34, 'total_tokens': 475, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", name='mimicking', id='754879b8-225b-4a3b-8cec-a690f679f044', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", additional_kwargs={}, response_metadata={}, name='mimicking', id='4d5ed412-2709-4106-9c1e-ff4a8b53cc45', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), AIMessage(content='Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\\n\\n| Trial ID | Title                                                                                                            | Disorder     | Drug             |\\n|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\\n| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\\n| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\\n| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\\n| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\\n| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\\n\\nThese trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.', additional_kwargs={'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'query': \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", 'execute_result': [[20297, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran.', 'Fascioliasis', 'triclabendazole'], [20298, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile.', 'Fascioliasis', 'triclabendazole'], [20299, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba.', 'Fascioliasis', 'triclabendazole'], [20300, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia.', 'Fascioliasis', 'triclabendazole'], [20301, 'Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke).', 'Fascioliasis', 'triclabendazole']]}, response_metadata={}, id='dd184c63-e0ec-41aa-9398-8648ae918d83', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content='The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV', additional_kwargs={}, response_metadata={}, id='168c56b2-77e8-4b14-b21b-af03ef8135c0'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1418, 'total_tokens': 1437, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-65d48a4a-01aa-4455-acaf-42508150fa42-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1418, 'output_tokens': 19, 'total_tokens': 1437, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='updated concept', name='memory', id='6cd4f9f8-8510-4314-b5a1-6d115e93ae7e', tool_call_id='call_BbnYMzW6NWuYXHItZSSTlNqY'), HumanMessage(content='We also define \"the Market leader\" company as GSK', additional_kwargs={}, response_metadata={}, id='722645df-bc28-4f5d-8a2b-dec008bc7363'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1464, 'total_tokens': 1483, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6951dbc0-47d3-42b7-9009-84fe6f6c7a5b-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1464, 'output_tokens': 19, 'total_tokens': 1483, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='updated concept', name='memory', id='598bd5fe-57a7-4b40-a13b-ec9fb44fe684', tool_call_id='call_6C8SUAwzy1H8bR2dkG6hrUnB'), HumanMessage(content='Tabulate the amount of trials sponsored by \"the Three small guys\".', additional_kwargs={}, response_metadata={}, id='fbc12694-32e1-4e69-94c7-16d6448aa025', tool_choice='sql'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1512, 'total_tokens': 1531, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-91cdf93c-3fe6-460a-bcb0-faeaa1146b64-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1512, 'output_tokens': 19, 'total_tokens': 1531, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='49431405-61a8-4462-9339-4c0333e23171', tool_call_id='call_FixZDNScYgtmHjosgoJwOIyC'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_AldpqkdPBSnKknGTCVDWjS7c', 'function': {'arguments': '{\"question\":\"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN (\\'Astellas\\', \\'Novartis\\', \\'ViiV\\') GROUP BY Sponsor\",\"top_k\":50}', 'name': 'sql'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 1017, 'total_tokens': 1065, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-88cb5860-7e1d-4f10-821c-aaca16ec7bce-0', tool_calls=[{'name': 'sql', 'args': {'question': \"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') GROUP BY Sponsor\", 'top_k': 50}, 'id': 'call_AldpqkdPBSnKknGTCVDWjS7c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1017, 'output_tokens': 48, 'total_tokens': 1065, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", name='sql', id='706718d3-c92f-4c59-b654-0b56d1718e8f', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'), HumanMessage(content=\"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='sql', id='652020e6-838a-42a7-aa08-6cfc6eabfa4f', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'), AIMessage(content='Here are the results formatted into sentences:\\n\\n- Astellas has conducted 101 trials.\\n- Novartis has conducted 239 trials.\\n- ViiV has conducted 76 trials.\\n\\nAlternatively, the results can be presented in a table format:\\n\\n| Sponsor   | TrialCount |\\n|-----------|------------|\\n| Astellas  | 101        |\\n| Novartis  | 239        |\\n| ViiV     | 76         |', additional_kwargs={'question': \"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') GROUP BY Sponsor\", 'query': \"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", 'execute_result': [['Astellas', 101], ['Novartis', 239], ['ViiV', 76]]}, response_metadata={}, id='004b9990-363b-4ee0-8dd0-f50e2cf6c177', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'), HumanMessage(content='Calculate the amount of trials sponsored by the market leader.', additional_kwargs={}, response_metadata={}, id='5f1c616b-8e49-4e3d-9c4e-7bbc3f874fd4', tool_choice='sql'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_XzJ41uh35e3DbUk1gtc6L9t1', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1790, 'total_tokens': 1809, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1408}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c03e4533-dea4-4242-bd34-8efe2afcebba-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_XzJ41uh35e3DbUk1gtc6L9t1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1790, 'output_tokens': 19, 'total_tokens': 1809, 'input_token_details': {'audio': 0, 'cache_read': 1408}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "len(message.tool_calls) =  1\n",
      "---route_message---\n",
      " tool_call: {'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_XzJ41uh35e3DbUk1gtc6L9t1', 'type': 'tool_call'}\n",
      "***********select_query_tool\n",
      "len: 29\n",
      "---select_query_tool---\n",
      "I captured the tool_call_id call_XzJ41uh35e3DbUk1gtc6L9t1\n",
      "len: 30\n",
      "---call_tool_to_generate_query---\n",
      "---call_tool_to_generate_query---\n",
      "obj_tools: [StructuredTool(name='sql', description='Use the SQL route to get the answer from the database. It can find data across all tables. Consider it as the default tool. top_k is the number of results to return.', args_schema=<class 'langchain_core.utils.pydantic.sql'>, func=<function sql at 0x10af79620>)]\n",
      "existing_memories [{'name': 'Three Small Guys', 'items': ['Astellas', 'Novartis', 'ViiV']}, {'name': 'the Market leader', 'items': ['GSK']}]\n",
      "++++++++---In agent\n",
      "messages: [HumanMessage(content='What diseases can hydroflumethiazide treat?', additional_kwargs={}, response_metadata={}, id='4a5b31cb-5ab5-4f81-a04e-43bb334139ac', tool_choice='graph'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='9e4e6b47-7abc-44f2-aa9e-31e0f9478587', tool_call_id='call_YTIZsoSW3e0LyVmmJpGr25DV'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'function': {'arguments': '{\"question\":\"What diseases can hydroflumethiazide treat?\",\"top_k\":50}', 'name': 'graph'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 205, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e59d835d-8d04-43f2-9377-6ed9a0bde163-0', tool_calls=[{'name': 'graph', 'args': {'question': 'What diseases can hydroflumethiazide treat?', 'top_k': 50}, 'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 205, 'output_tokens': 28, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", name='graph', id='d2d3b37c-ce8f-4f4f-b04b-250b43344e96', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='graph', id='fff233cb-da4d-4c72-b376-6042bca9d72c', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), AIMessage(content='Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', additional_kwargs={'question': 'What diseases can hydroflumethiazide treat?', 'query': \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'execute_result': [['Hypertensive disease'], ['Glomerulonephritis'], ['Heart failure'], ['Edema'], ['Kidney Failure'], ['Nephrotic Syndrome'], ['Liver Cirrhosis']]}, response_metadata={}, id='a5be0b97-ad85-4671-a199-71d2bad0e031', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content='Show 5 trials that tested drugs against the top 7 liver-related disorders', additional_kwargs={}, response_metadata={}, id='309995b9-7d79-441d-97be-70248bbb8522', tool_choice='mimicking'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 632, 'total_tokens': 651, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e2d2c45b-b39a-4099-99d8-60453bcb4698-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 632, 'output_tokens': 19, 'total_tokens': 651, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='41e094bc-08a8-4401-af40-e2600224565c', tool_call_id='call_4mTVMhHDl0QemMmmHuBRhZTP'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'function': {'arguments': '{\"question\":\"Show 5 trials that tested drugs against the top 7 liver-related disorders\",\"top_k\":5}', 'name': 'mimicking'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 441, 'total_tokens': 475, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-db90e46b-c064-4c39-ac48-9b5d40f60958-0', tool_calls=[{'name': 'mimicking', 'args': {'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'top_k': 5}, 'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 441, 'output_tokens': 34, 'total_tokens': 475, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", name='mimicking', id='754879b8-225b-4a3b-8cec-a690f679f044', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", additional_kwargs={}, response_metadata={}, name='mimicking', id='4d5ed412-2709-4106-9c1e-ff4a8b53cc45', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), AIMessage(content='Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\\n\\n| Trial ID | Title                                                                                                            | Disorder     | Drug             |\\n|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\\n| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\\n| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\\n| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\\n| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\\n| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\\n\\nThese trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.', additional_kwargs={'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'query': \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", 'execute_result': [[20297, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran.', 'Fascioliasis', 'triclabendazole'], [20298, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile.', 'Fascioliasis', 'triclabendazole'], [20299, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba.', 'Fascioliasis', 'triclabendazole'], [20300, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia.', 'Fascioliasis', 'triclabendazole'], [20301, 'Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke).', 'Fascioliasis', 'triclabendazole']]}, response_metadata={}, id='dd184c63-e0ec-41aa-9398-8648ae918d83', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content='The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV', additional_kwargs={}, response_metadata={}, id='168c56b2-77e8-4b14-b21b-af03ef8135c0'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1418, 'total_tokens': 1437, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-65d48a4a-01aa-4455-acaf-42508150fa42-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1418, 'output_tokens': 19, 'total_tokens': 1437, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='updated concept', name='memory', id='6cd4f9f8-8510-4314-b5a1-6d115e93ae7e', tool_call_id='call_BbnYMzW6NWuYXHItZSSTlNqY'), HumanMessage(content='We also define \"the Market leader\" company as GSK', additional_kwargs={}, response_metadata={}, id='722645df-bc28-4f5d-8a2b-dec008bc7363'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1464, 'total_tokens': 1483, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6951dbc0-47d3-42b7-9009-84fe6f6c7a5b-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1464, 'output_tokens': 19, 'total_tokens': 1483, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='updated concept', name='memory', id='598bd5fe-57a7-4b40-a13b-ec9fb44fe684', tool_call_id='call_6C8SUAwzy1H8bR2dkG6hrUnB'), HumanMessage(content='Tabulate the amount of trials sponsored by \"the Three small guys\".', additional_kwargs={}, response_metadata={}, id='fbc12694-32e1-4e69-94c7-16d6448aa025', tool_choice='sql'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1512, 'total_tokens': 1531, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-91cdf93c-3fe6-460a-bcb0-faeaa1146b64-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1512, 'output_tokens': 19, 'total_tokens': 1531, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='49431405-61a8-4462-9339-4c0333e23171', tool_call_id='call_FixZDNScYgtmHjosgoJwOIyC'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_AldpqkdPBSnKknGTCVDWjS7c', 'function': {'arguments': '{\"question\":\"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN (\\'Astellas\\', \\'Novartis\\', \\'ViiV\\') GROUP BY Sponsor\",\"top_k\":50}', 'name': 'sql'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 1017, 'total_tokens': 1065, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-88cb5860-7e1d-4f10-821c-aaca16ec7bce-0', tool_calls=[{'name': 'sql', 'args': {'question': \"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') GROUP BY Sponsor\", 'top_k': 50}, 'id': 'call_AldpqkdPBSnKknGTCVDWjS7c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1017, 'output_tokens': 48, 'total_tokens': 1065, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", name='sql', id='706718d3-c92f-4c59-b654-0b56d1718e8f', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'), HumanMessage(content=\"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='sql', id='652020e6-838a-42a7-aa08-6cfc6eabfa4f', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'), AIMessage(content='Here are the results formatted into sentences:\\n\\n- Astellas has conducted 101 trials.\\n- Novartis has conducted 239 trials.\\n- ViiV has conducted 76 trials.\\n\\nAlternatively, the results can be presented in a table format:\\n\\n| Sponsor   | TrialCount |\\n|-----------|------------|\\n| Astellas  | 101        |\\n| Novartis  | 239        |\\n| ViiV     | 76         |', additional_kwargs={'question': \"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') GROUP BY Sponsor\", 'query': \"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", 'execute_result': [['Astellas', 101], ['Novartis', 239], ['ViiV', 76]]}, response_metadata={}, id='004b9990-363b-4ee0-8dd0-f50e2cf6c177', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'), HumanMessage(content='Calculate the amount of trials sponsored by the market leader.', additional_kwargs={}, response_metadata={}, id='5f1c616b-8e49-4e3d-9c4e-7bbc3f874fd4', tool_choice='sql'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_XzJ41uh35e3DbUk1gtc6L9t1', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1790, 'total_tokens': 1809, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1408}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c03e4533-dea4-4242-bd34-8efe2afcebba-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_XzJ41uh35e3DbUk1gtc6L9t1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1790, 'output_tokens': 19, 'total_tokens': 1809, 'input_token_details': {'audio': 0, 'cache_read': 1408}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', tool_call_id='call_XzJ41uh35e3DbUk1gtc6L9t1')]\n",
      "++++++++---last_msg ['Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', 'Show 5 trials that tested drugs against the top 7 liver-related disorders', \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", 'Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\\n\\n| Trial ID | Title                                                                                                            | Disorder     | Drug             |\\n|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\\n| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\\n| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\\n| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\\n| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\\n| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\\n\\nThese trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.', 'The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV', 'We also define \"the Market leader\" company as GSK', 'Tabulate the amount of trials sponsored by \"the Three small guys\".', \"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", 'Here are the results formatted into sentences:\\n\\n- Astellas has conducted 101 trials.\\n- Novartis has conducted 239 trials.\\n- ViiV has conducted 76 trials.\\n\\nAlternatively, the results can be presented in a table format:\\n\\n| Sponsor   | TrialCount |\\n|-----------|------------|\\n| Astellas  | 101        |\\n| Novartis  | 239        |\\n| ViiV     | 76         |', 'Calculate the amount of trials sponsored by the market leader.']\n",
      "++++++++---In agent\n",
      "system_msg [SystemMessage(content=\"You are a helpful assistant tasked with performing RAG with a drug-trial DuckDB as backend. \\n                            Capture both the question and the amount of results 'top_k' that the user want to see. If the user does not specify the amount, set top_k = 50.\\n                            Only one query for one question. Do not break the question into multiple queries.\\n                            If the user has defined some concepts or terms, use them in your query faithfully to personalize your responses.\\n                            Here is the memory (it may be empty): \\n Three Small Guys: ['Astellas', 'Novartis', 'ViiV']\\n the Market leader: ['GSK']\\n\", additional_kwargs={}, response_metadata={}), 'Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', 'Show 5 trials that tested drugs against the top 7 liver-related disorders', \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", 'Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\\n\\n| Trial ID | Title                                                                                                            | Disorder     | Drug             |\\n|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\\n| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\\n| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\\n| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\\n| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\\n| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\\n\\nThese trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.', 'The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV', 'We also define \"the Market leader\" company as GSK', 'Tabulate the amount of trials sponsored by \"the Three small guys\".', \"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", 'Here are the results formatted into sentences:\\n\\n- Astellas has conducted 101 trials.\\n- Novartis has conducted 239 trials.\\n- ViiV has conducted 76 trials.\\n\\nAlternatively, the results can be presented in a table format:\\n\\n| Sponsor   | TrialCount |\\n|-----------|------------|\\n| Astellas  | 101        |\\n| Novartis  | 239        |\\n| ViiV     | 76         |', 'Calculate the amount of trials sponsored by the market leader.']\n",
      "++++++++---In agent, agent_response content='' additional_kwargs={'tool_calls': [{'id': 'call_ERn85u25GzjIPLqhOXTWPAhz', 'function': {'arguments': '{\"question\":\"Calculate the amount of trials sponsored by GSK.\",\"top_k\":50}', 'name': 'sql'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 1090, 'total_tokens': 1116, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-aeaa305c-339f-4957-acbf-cb65424243d6-0' tool_calls=[{'name': 'sql', 'args': {'question': 'Calculate the amount of trials sponsored by GSK.', 'top_k': 50}, 'id': 'call_ERn85u25GzjIPLqhOXTWPAhz', 'type': 'tool_call'}] usage_metadata={'input_tokens': 1090, 'output_tokens': 26, 'total_tokens': 1116, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "len: 31\n",
      "==== sql ====\n",
      "sql question Calculate the amount of trials sponsored by GSK. top_k 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: PostgreSQL format_type() returned NULL for column 'definitionEmbedding'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'drug_cui'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'drug_names'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'source_pk'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'source_fk'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'destination_pk'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'destination_fk'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:600: SAWarning: Did not recognize type 'list' of column 'sub_labels'\n",
      "  columns = self._get_columns_info(rows, domains, enums, schema)  # type: ignore[attr-defined]\n",
      "/Users/dgg32/anaconda3/envs/langgraph/lib/python3.13/site-packages/duckdb_engine/__init__.py:174: DuckDBEngineWarning: duckdb-engine doesn't yet support reflection on indices\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write_query first=RunnableAssign(mapper={\n",
      "  input: RunnableLambda(...),\n",
      "  table_info: RunnableLambda(...)\n",
      "}) middle=[RunnableLambda(lambda x: {k: v for k, v in x.items() if k not in ('question', 'table_names_to_use')}), FewShotPromptTemplate(input_variables=['input', 'table_info'], input_types={}, partial_variables={'top_k': '5'}, example_selector=SemanticSimilarityExampleSelector(vectorstore=<langchain_community.vectorstores.lancedb.LanceDB object at 0x12819eea0>, k=5, example_keys=None, input_keys=['input'], vectorstore_kwargs=None), example_prompt=PromptTemplate(input_variables=['input', 'query'], input_types={}, partial_variables={}, template='User input: {input}\\nSQL query: {query}'), suffix='User input: {input}\\nSQL query: ', prefix=\"You are a DuckDB expert. Given an input question, create a syntactically correct DuckDB query to run. Ignore the {top_k} parameter for now.\\n        Here is the relevant table info: {table_info}\\n        - If the search term contains a single quote, it should be escaped with another single quote. For example, 'Alzheimer's Disease' should be 'Alzheimer''s Disease'.\\n        - Only return SQL Query not anything else like ```sql ... ```\\n        - Using NOT IN with NULL values\\n        - Using UNION when UNION ALL should have been used\\n        - Using BETWEEN for exclusive ranges\\n        - Data type mismatch in predicates\\n        - Using the correct number of arguments for functions\\n        - Casting to the correct data type\\n        - Using the proper columns for joins\\n        - Never write a LIMIT clause.\\n        - Make sure all parentheses are balanced.\\n        - Ends with a semicolon\\n        - Output the final SQL query only.\\n        Below are a number of examples of questions and their corresponding SQL queries.\"), RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10af73620>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10af77230>, root_client=<openai.OpenAI object at 0x10ad2bcb0>, root_async_client=<openai.AsyncOpenAI object at 0x10af73770>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'stop': ['\\nSQLResult:']}, config={}, config_factories=[]), StrOutputParser()] last=RunnableLambda(_strip)\n",
      "len: 32\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"sixing\"}}\n",
    "\n",
    "input_message = HumanMessage(\n",
    "    #content=\"\"\"Tabulate the amount of trials sponsored by \"the Three small guys\".\"\"\", tool_choice=\"sql\"\n",
    "    content=\"\"\"Calculate the amount of trials sponsored by the market leader.\"\"\", tool_choice=\"sql\"\n",
    ")\n",
    "\n",
    "for event in graph_definition.app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    print (\"len:\", len(event[\"messages\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"SELECT COUNT(PostingID) AS trial_count \\nFROM Trials \\nWHERE LOWER(Sponsor) = LOWER('GSK')\\n LIMIT 50;\" name='sql' id='773f4dd9-0964-4695-b77a-8d9ef81c7881' tool_call_id='call_ERn85u25GzjIPLqhOXTWPAhz'\n",
      "---execute_query_and_answer---\n",
      "question Calculate the amount of trials sponsored by GSK.\n",
      "query SELECT COUNT(PostingID) AS trial_count \n",
      "FROM Trials \n",
      "WHERE LOWER(Sponsor) = LOWER('GSK')\n",
      " LIMIT 50;\n",
      "m human content=\"SELECT COUNT(PostingID) AS trial_count \\nFROM Trials \\nWHERE LOWER(Sponsor) = LOWER('GSK')\\n LIMIT 50;\" additional_kwargs={} response_metadata={} name='sql' id='ca4bc251-c95a-4b5d-bd78-12bc0029200e' tool_call_id='call_ERn85u25GzjIPLqhOXTWPAhz'\n",
      "m tool content=\"SELECT COUNT(PostingID) AS trial_count \\nFROM Trials \\nWHERE LOWER(Sponsor) = LOWER('GSK')\\n LIMIT 50;\" name='sql' id='773f4dd9-0964-4695-b77a-8d9ef81c7881' tool_call_id='call_ERn85u25GzjIPLqhOXTWPAhz'\n",
      "return tool_call_id call_ERn85u25GzjIPLqhOXTWPAhz\n",
      "The amount of trials sponsored by GSK is 1705. \n",
      "\n",
      "Here is the information formatted in a table:\n",
      "\n",
      "| Sponsor | Number of Trials |\n",
      "|---------|------------------|\n",
      "| GSK     | 1705             |\n"
     ]
    }
   ],
   "source": [
    "print (graph_definition.app.get_state(config).values[\"messages\"][-1])\n",
    "\n",
    "tool_call_id = graph_definition.app.get_state(config).values[\"messages\"][-1].tool_call_id\n",
    "tool_name = graph_definition.app.get_state(config).values[\"messages\"][-1].name\n",
    "tool_content = graph_definition.app.get_state(config).values[\"messages\"][-1].content\n",
    "\n",
    "# We now create the tool call with the id and the response we want\n",
    "tool_message = [\n",
    "    {\"tool_call_id\": tool_call_id, \"name\": tool_name, \n",
    "     #\"type\": \"tool\",\n",
    "     \"type\": \"human\",\n",
    "    \"content\": tool_content}\n",
    "]\n",
    "\n",
    "# # This is equivalent to the below, either one works\n",
    "# from langchain_core.messages import ToolMessage\n",
    "# tool_message = [ToolMessage(tool_call_id=tool_call_id, content=\"san francisco\")]\n",
    "\n",
    "# We now update the state\n",
    "# Notice that we are also specifying `as_node=\"ask_human\"`\n",
    "# This will apply this update as this node,\n",
    "# which will make it so that afterwards it continues as normal\n",
    "graph_definition.app.update_state(config, {\"messages\": tool_message}, as_node=\"human_feedback\")\n",
    "events = list(graph_definition.app.stream(None, config, stream_mode=\"values\"))\n",
    "last_event = events[-1]\n",
    "print (last_event[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'messages': [HumanMessage(content='What diseases can hydroflumethiazide treat?', additional_kwargs={}, response_metadata={}, id='4a5b31cb-5ab5-4f81-a04e-43bb334139ac', tool_choice='graph'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content='', id='9e4e6b47-7abc-44f2-aa9e-31e0f9478587', tool_call_id='call_YTIZsoSW3e0LyVmmJpGr25DV'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'function': {'arguments': '{\"question\":\"What diseases can hydroflumethiazide treat?\",\"top_k\":50}', 'name': 'graph'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 205, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e59d835d-8d04-43f2-9377-6ed9a0bde163-0', tool_calls=[{'name': 'graph', 'args': {'question': 'What diseases can hydroflumethiazide treat?', 'top_k': 50}, 'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 205, 'output_tokens': 28, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", name='graph', id='d2d3b37c-ce8f-4f4f-b04b-250b43344e96', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'),\n",
       "   HumanMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='graph', id='fff233cb-da4d-4c72-b376-6042bca9d72c', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'),\n",
       "   AIMessage(content='Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', additional_kwargs={'question': 'What diseases can hydroflumethiazide treat?', 'query': \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'execute_result': [['Hypertensive disease'], ['Glomerulonephritis'], ['Heart failure'], ['Edema'], ['Kidney Failure'], ['Nephrotic Syndrome'], ['Liver Cirrhosis']]}, response_metadata={}, id='a5be0b97-ad85-4671-a199-71d2bad0e031', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'),\n",
       "   HumanMessage(content='Show 5 trials that tested drugs against the top 7 liver-related disorders', additional_kwargs={}, response_metadata={}, id='309995b9-7d79-441d-97be-70248bbb8522', tool_choice='mimicking'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 632, 'total_tokens': 651, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e2d2c45b-b39a-4099-99d8-60453bcb4698-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 632, 'output_tokens': 19, 'total_tokens': 651, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content='', id='41e094bc-08a8-4401-af40-e2600224565c', tool_call_id='call_4mTVMhHDl0QemMmmHuBRhZTP'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'function': {'arguments': '{\"question\":\"Show 5 trials that tested drugs against the top 7 liver-related disorders\",\"top_k\":5}', 'name': 'mimicking'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 441, 'total_tokens': 475, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-db90e46b-c064-4c39-ac48-9b5d40f60958-0', tool_calls=[{'name': 'mimicking', 'args': {'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'top_k': 5}, 'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 441, 'output_tokens': 34, 'total_tokens': 475, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", name='mimicking', id='754879b8-225b-4a3b-8cec-a690f679f044', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'),\n",
       "   HumanMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", additional_kwargs={}, response_metadata={}, name='mimicking', id='4d5ed412-2709-4106-9c1e-ff4a8b53cc45', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'),\n",
       "   AIMessage(content='Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\\n\\n| Trial ID | Title                                                                                                            | Disorder     | Drug             |\\n|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\\n| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\\n| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\\n| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\\n| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\\n| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\\n\\nThese trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.', additional_kwargs={'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'query': \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", 'execute_result': [[20297, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran.', 'Fascioliasis', 'triclabendazole'], [20298, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile.', 'Fascioliasis', 'triclabendazole'], [20299, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba.', 'Fascioliasis', 'triclabendazole'], [20300, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia.', 'Fascioliasis', 'triclabendazole'], [20301, 'Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke).', 'Fascioliasis', 'triclabendazole']]}, response_metadata={}, id='dd184c63-e0ec-41aa-9398-8648ae918d83', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'),\n",
       "   HumanMessage(content='The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV', additional_kwargs={}, response_metadata={}, id='168c56b2-77e8-4b14-b21b-af03ef8135c0'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1418, 'total_tokens': 1437, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-65d48a4a-01aa-4455-acaf-42508150fa42-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1418, 'output_tokens': 19, 'total_tokens': 1437, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content='updated concept', name='memory', id='6cd4f9f8-8510-4314-b5a1-6d115e93ae7e', tool_call_id='call_BbnYMzW6NWuYXHItZSSTlNqY'),\n",
       "   HumanMessage(content='We also define \"the Market leader\" company as GSK', additional_kwargs={}, response_metadata={}, id='722645df-bc28-4f5d-8a2b-dec008bc7363'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1464, 'total_tokens': 1483, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6951dbc0-47d3-42b7-9009-84fe6f6c7a5b-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1464, 'output_tokens': 19, 'total_tokens': 1483, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content='updated concept', name='memory', id='598bd5fe-57a7-4b40-a13b-ec9fb44fe684', tool_call_id='call_6C8SUAwzy1H8bR2dkG6hrUnB'),\n",
       "   HumanMessage(content='Tabulate the amount of trials sponsored by \"the Three small guys\".', additional_kwargs={}, response_metadata={}, id='fbc12694-32e1-4e69-94c7-16d6448aa025', tool_choice='sql'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1512, 'total_tokens': 1531, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-91cdf93c-3fe6-460a-bcb0-faeaa1146b64-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1512, 'output_tokens': 19, 'total_tokens': 1531, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content='', id='49431405-61a8-4462-9339-4c0333e23171', tool_call_id='call_FixZDNScYgtmHjosgoJwOIyC'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_AldpqkdPBSnKknGTCVDWjS7c', 'function': {'arguments': '{\"question\":\"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN (\\'Astellas\\', \\'Novartis\\', \\'ViiV\\') GROUP BY Sponsor\",\"top_k\":50}', 'name': 'sql'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 1017, 'total_tokens': 1065, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-88cb5860-7e1d-4f10-821c-aaca16ec7bce-0', tool_calls=[{'name': 'sql', 'args': {'question': \"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') GROUP BY Sponsor\", 'top_k': 50}, 'id': 'call_AldpqkdPBSnKknGTCVDWjS7c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1017, 'output_tokens': 48, 'total_tokens': 1065, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content=\"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", name='sql', id='706718d3-c92f-4c59-b654-0b56d1718e8f', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'),\n",
       "   HumanMessage(content=\"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='sql', id='652020e6-838a-42a7-aa08-6cfc6eabfa4f', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'),\n",
       "   AIMessage(content='Here are the results formatted into sentences:\\n\\n- Astellas has conducted 101 trials.\\n- Novartis has conducted 239 trials.\\n- ViiV has conducted 76 trials.\\n\\nAlternatively, the results can be presented in a table format:\\n\\n| Sponsor   | TrialCount |\\n|-----------|------------|\\n| Astellas  | 101        |\\n| Novartis  | 239        |\\n| ViiV     | 76         |', additional_kwargs={'question': \"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') GROUP BY Sponsor\", 'query': \"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", 'execute_result': [['Astellas', 101], ['Novartis', 239], ['ViiV', 76]]}, response_metadata={}, id='004b9990-363b-4ee0-8dd0-f50e2cf6c177', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'),\n",
       "   HumanMessage(content='Calculate the amount of trials sponsored by the market leader.', additional_kwargs={}, response_metadata={}, id='5f1c616b-8e49-4e3d-9c4e-7bbc3f874fd4', tool_choice='sql'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_XzJ41uh35e3DbUk1gtc6L9t1', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1790, 'total_tokens': 1809, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1408}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c03e4533-dea4-4242-bd34-8efe2afcebba-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_XzJ41uh35e3DbUk1gtc6L9t1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1790, 'output_tokens': 19, 'total_tokens': 1809, 'input_token_details': {'audio': 0, 'cache_read': 1408}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content='', id='7e78f81f-4a83-43ee-9cea-586fb2993495', tool_call_id='call_XzJ41uh35e3DbUk1gtc6L9t1'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ERn85u25GzjIPLqhOXTWPAhz', 'function': {'arguments': '{\"question\":\"Calculate the amount of trials sponsored by GSK.\",\"top_k\":50}', 'name': 'sql'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 1090, 'total_tokens': 1116, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-aeaa305c-339f-4957-acbf-cb65424243d6-0', tool_calls=[{'name': 'sql', 'args': {'question': 'Calculate the amount of trials sponsored by GSK.', 'top_k': 50}, 'id': 'call_ERn85u25GzjIPLqhOXTWPAhz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1090, 'output_tokens': 26, 'total_tokens': 1116, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content=\"SELECT COUNT(PostingID) AS trial_count \\nFROM Trials \\nWHERE LOWER(Sponsor) = LOWER('GSK')\\n LIMIT 50;\", name='sql', id='773f4dd9-0964-4695-b77a-8d9ef81c7881', tool_call_id='call_ERn85u25GzjIPLqhOXTWPAhz'),\n",
       "   HumanMessage(content=\"SELECT COUNT(PostingID) AS trial_count \\nFROM Trials \\nWHERE LOWER(Sponsor) = LOWER('GSK')\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='sql', id='ca4bc251-c95a-4b5d-bd78-12bc0029200e', tool_call_id='call_ERn85u25GzjIPLqhOXTWPAhz')],\n",
       "  'selected_tools': ['sql']},\n",
       " {'messages': [HumanMessage(content='What diseases can hydroflumethiazide treat?', additional_kwargs={}, response_metadata={}, id='4a5b31cb-5ab5-4f81-a04e-43bb334139ac', tool_choice='graph'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content='', id='9e4e6b47-7abc-44f2-aa9e-31e0f9478587', tool_call_id='call_YTIZsoSW3e0LyVmmJpGr25DV'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'function': {'arguments': '{\"question\":\"What diseases can hydroflumethiazide treat?\",\"top_k\":50}', 'name': 'graph'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 205, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e59d835d-8d04-43f2-9377-6ed9a0bde163-0', tool_calls=[{'name': 'graph', 'args': {'question': 'What diseases can hydroflumethiazide treat?', 'top_k': 50}, 'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 205, 'output_tokens': 28, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", name='graph', id='d2d3b37c-ce8f-4f4f-b04b-250b43344e96', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'),\n",
       "   HumanMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='graph', id='fff233cb-da4d-4c72-b376-6042bca9d72c', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'),\n",
       "   AIMessage(content='Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', additional_kwargs={'question': 'What diseases can hydroflumethiazide treat?', 'query': \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'execute_result': [['Hypertensive disease'], ['Glomerulonephritis'], ['Heart failure'], ['Edema'], ['Kidney Failure'], ['Nephrotic Syndrome'], ['Liver Cirrhosis']]}, response_metadata={}, id='a5be0b97-ad85-4671-a199-71d2bad0e031', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'),\n",
       "   HumanMessage(content='Show 5 trials that tested drugs against the top 7 liver-related disorders', additional_kwargs={}, response_metadata={}, id='309995b9-7d79-441d-97be-70248bbb8522', tool_choice='mimicking'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 632, 'total_tokens': 651, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e2d2c45b-b39a-4099-99d8-60453bcb4698-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 632, 'output_tokens': 19, 'total_tokens': 651, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content='', id='41e094bc-08a8-4401-af40-e2600224565c', tool_call_id='call_4mTVMhHDl0QemMmmHuBRhZTP'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'function': {'arguments': '{\"question\":\"Show 5 trials that tested drugs against the top 7 liver-related disorders\",\"top_k\":5}', 'name': 'mimicking'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 441, 'total_tokens': 475, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-db90e46b-c064-4c39-ac48-9b5d40f60958-0', tool_calls=[{'name': 'mimicking', 'args': {'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'top_k': 5}, 'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 441, 'output_tokens': 34, 'total_tokens': 475, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", name='mimicking', id='754879b8-225b-4a3b-8cec-a690f679f044', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'),\n",
       "   HumanMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", additional_kwargs={}, response_metadata={}, name='mimicking', id='4d5ed412-2709-4106-9c1e-ff4a8b53cc45', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'),\n",
       "   AIMessage(content='Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\\n\\n| Trial ID | Title                                                                                                            | Disorder     | Drug             |\\n|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\\n| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\\n| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\\n| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\\n| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\\n| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\\n\\nThese trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.', additional_kwargs={'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'query': \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", 'execute_result': [[20297, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran.', 'Fascioliasis', 'triclabendazole'], [20298, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile.', 'Fascioliasis', 'triclabendazole'], [20299, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba.', 'Fascioliasis', 'triclabendazole'], [20300, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia.', 'Fascioliasis', 'triclabendazole'], [20301, 'Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke).', 'Fascioliasis', 'triclabendazole']]}, response_metadata={}, id='dd184c63-e0ec-41aa-9398-8648ae918d83', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'),\n",
       "   HumanMessage(content='The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV', additional_kwargs={}, response_metadata={}, id='168c56b2-77e8-4b14-b21b-af03ef8135c0'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1418, 'total_tokens': 1437, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-65d48a4a-01aa-4455-acaf-42508150fa42-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1418, 'output_tokens': 19, 'total_tokens': 1437, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content='updated concept', name='memory', id='6cd4f9f8-8510-4314-b5a1-6d115e93ae7e', tool_call_id='call_BbnYMzW6NWuYXHItZSSTlNqY'),\n",
       "   HumanMessage(content='We also define \"the Market leader\" company as GSK', additional_kwargs={}, response_metadata={}, id='722645df-bc28-4f5d-8a2b-dec008bc7363'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1464, 'total_tokens': 1483, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6951dbc0-47d3-42b7-9009-84fe6f6c7a5b-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1464, 'output_tokens': 19, 'total_tokens': 1483, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content='updated concept', name='memory', id='598bd5fe-57a7-4b40-a13b-ec9fb44fe684', tool_call_id='call_6C8SUAwzy1H8bR2dkG6hrUnB'),\n",
       "   HumanMessage(content='Tabulate the amount of trials sponsored by \"the Three small guys\".', additional_kwargs={}, response_metadata={}, id='fbc12694-32e1-4e69-94c7-16d6448aa025', tool_choice='sql'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1512, 'total_tokens': 1531, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-91cdf93c-3fe6-460a-bcb0-faeaa1146b64-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1512, 'output_tokens': 19, 'total_tokens': 1531, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content='', id='49431405-61a8-4462-9339-4c0333e23171', tool_call_id='call_FixZDNScYgtmHjosgoJwOIyC'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_AldpqkdPBSnKknGTCVDWjS7c', 'function': {'arguments': '{\"question\":\"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN (\\'Astellas\\', \\'Novartis\\', \\'ViiV\\') GROUP BY Sponsor\",\"top_k\":50}', 'name': 'sql'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 1017, 'total_tokens': 1065, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-88cb5860-7e1d-4f10-821c-aaca16ec7bce-0', tool_calls=[{'name': 'sql', 'args': {'question': \"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') GROUP BY Sponsor\", 'top_k': 50}, 'id': 'call_AldpqkdPBSnKknGTCVDWjS7c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1017, 'output_tokens': 48, 'total_tokens': 1065, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content=\"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", name='sql', id='706718d3-c92f-4c59-b654-0b56d1718e8f', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'),\n",
       "   HumanMessage(content=\"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='sql', id='652020e6-838a-42a7-aa08-6cfc6eabfa4f', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'),\n",
       "   AIMessage(content='Here are the results formatted into sentences:\\n\\n- Astellas has conducted 101 trials.\\n- Novartis has conducted 239 trials.\\n- ViiV has conducted 76 trials.\\n\\nAlternatively, the results can be presented in a table format:\\n\\n| Sponsor   | TrialCount |\\n|-----------|------------|\\n| Astellas  | 101        |\\n| Novartis  | 239        |\\n| ViiV     | 76         |', additional_kwargs={'question': \"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') GROUP BY Sponsor\", 'query': \"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", 'execute_result': [['Astellas', 101], ['Novartis', 239], ['ViiV', 76]]}, response_metadata={}, id='004b9990-363b-4ee0-8dd0-f50e2cf6c177', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'),\n",
       "   HumanMessage(content='Calculate the amount of trials sponsored by the market leader.', additional_kwargs={}, response_metadata={}, id='5f1c616b-8e49-4e3d-9c4e-7bbc3f874fd4', tool_choice='sql'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_XzJ41uh35e3DbUk1gtc6L9t1', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1790, 'total_tokens': 1809, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1408}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c03e4533-dea4-4242-bd34-8efe2afcebba-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_XzJ41uh35e3DbUk1gtc6L9t1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1790, 'output_tokens': 19, 'total_tokens': 1809, 'input_token_details': {'audio': 0, 'cache_read': 1408}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content='', id='7e78f81f-4a83-43ee-9cea-586fb2993495', tool_call_id='call_XzJ41uh35e3DbUk1gtc6L9t1'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ERn85u25GzjIPLqhOXTWPAhz', 'function': {'arguments': '{\"question\":\"Calculate the amount of trials sponsored by GSK.\",\"top_k\":50}', 'name': 'sql'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 1090, 'total_tokens': 1116, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-aeaa305c-339f-4957-acbf-cb65424243d6-0', tool_calls=[{'name': 'sql', 'args': {'question': 'Calculate the amount of trials sponsored by GSK.', 'top_k': 50}, 'id': 'call_ERn85u25GzjIPLqhOXTWPAhz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1090, 'output_tokens': 26, 'total_tokens': 1116, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "   ToolMessage(content=\"SELECT COUNT(PostingID) AS trial_count \\nFROM Trials \\nWHERE LOWER(Sponsor) = LOWER('GSK')\\n LIMIT 50;\", name='sql', id='773f4dd9-0964-4695-b77a-8d9ef81c7881', tool_call_id='call_ERn85u25GzjIPLqhOXTWPAhz'),\n",
       "   HumanMessage(content=\"SELECT COUNT(PostingID) AS trial_count \\nFROM Trials \\nWHERE LOWER(Sponsor) = LOWER('GSK')\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='sql', id='ca4bc251-c95a-4b5d-bd78-12bc0029200e', tool_call_id='call_ERn85u25GzjIPLqhOXTWPAhz'),\n",
       "   AIMessage(content='The amount of trials sponsored by GSK is 1705. \\n\\nHere is the information formatted in a table:\\n\\n| Sponsor | Number of Trials |\\n|---------|------------------|\\n| GSK     | 1705             |', additional_kwargs={'question': 'Calculate the amount of trials sponsored by GSK.', 'query': \"SELECT COUNT(PostingID) AS trial_count \\nFROM Trials \\nWHERE LOWER(Sponsor) = LOWER('GSK')\\n LIMIT 50;\", 'execute_result': [(1705,)]}, response_metadata={}, id='02b51180-9fa7-4681-9544-6263e70852f2', tool_call_id='call_ERn85u25GzjIPLqhOXTWPAhz')],\n",
       "  'selected_tools': ['sql']}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 35\n",
      "Before response\n",
      "---select_intent---\n",
      "response:  content=\"You're welcome! If you have any more questions or need further assistance, feel free to ask. Have a great day!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 1971, 'total_tokens': 1996, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1664}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None} id='run-3d70228f-8083-498b-acec-65957b6d3adb-0' usage_metadata={'input_tokens': 1971, 'output_tokens': 25, 'total_tokens': 1996, 'input_token_details': {'audio': 0, 'cache_read': 1664}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "---route_message---\n",
      " message: [HumanMessage(content='What diseases can hydroflumethiazide treat?', additional_kwargs={}, response_metadata={}, id='4a5b31cb-5ab5-4f81-a04e-43bb334139ac', tool_choice='graph'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 289, 'total_tokens': 308, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-33a38c60-be1e-4de6-8171-9e577478fbf1-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_YTIZsoSW3e0LyVmmJpGr25DV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 289, 'output_tokens': 19, 'total_tokens': 308, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='9e4e6b47-7abc-44f2-aa9e-31e0f9478587', tool_call_id='call_YTIZsoSW3e0LyVmmJpGr25DV'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'function': {'arguments': '{\"question\":\"What diseases can hydroflumethiazide treat?\",\"top_k\":50}', 'name': 'graph'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 205, 'total_tokens': 233, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e59d835d-8d04-43f2-9377-6ed9a0bde163-0', tool_calls=[{'name': 'graph', 'args': {'question': 'What diseases can hydroflumethiazide treat?', 'top_k': 50}, 'id': 'call_aWDuailOR4PHi3r1ad1EAMBK', 'type': 'tool_call'}], usage_metadata={'input_tokens': 205, 'output_tokens': 28, 'total_tokens': 233, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", name='graph', id='d2d3b37c-ce8f-4f4f-b04b-250b43344e96', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content=\"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='graph', id='fff233cb-da4d-4c72-b376-6042bca9d72c', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), AIMessage(content='Hydroflumethiazide can treat the following diseases:\\n\\n1. Hypertensive disease\\n2. Glomerulonephritis\\n3. Heart failure\\n4. Edema\\n5. Kidney Failure\\n6. Nephrotic Syndrome\\n7. Liver Cirrhosis\\n\\nAlternatively, here is the information presented in a table format:\\n\\n| Disease                |\\n|------------------------|\\n| Hypertensive disease    |\\n| Glomerulonephritis     |\\n| Heart failure           |\\n| Edema                  |\\n| Kidney Failure          |\\n| Nephrotic Syndrome      |\\n| Liver Cirrhosis        |', additional_kwargs={'question': 'What diseases can hydroflumethiazide treat?', 'query': \"FROM GRAPH_TABLE (drug_graph  \\n    MATCH  \\n        (i:Drug WHERE LOWER(i.name) = LOWER('hydroflumethiazide'))-[m:MAY_TREAT]->(c:Disorder)  \\n    COLUMNS (c.name AS disorder_name)  \\n    )\\n LIMIT 50;\", 'execute_result': [['Hypertensive disease'], ['Glomerulonephritis'], ['Heart failure'], ['Edema'], ['Kidney Failure'], ['Nephrotic Syndrome'], ['Liver Cirrhosis']]}, response_metadata={}, id='a5be0b97-ad85-4671-a199-71d2bad0e031', tool_call_id='call_aWDuailOR4PHi3r1ad1EAMBK'), HumanMessage(content='Show 5 trials that tested drugs against the top 7 liver-related disorders', additional_kwargs={}, response_metadata={}, id='309995b9-7d79-441d-97be-70248bbb8522', tool_choice='mimicking'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 632, 'total_tokens': 651, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e2d2c45b-b39a-4099-99d8-60453bcb4698-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_4mTVMhHDl0QemMmmHuBRhZTP', 'type': 'tool_call'}], usage_metadata={'input_tokens': 632, 'output_tokens': 19, 'total_tokens': 651, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='41e094bc-08a8-4401-af40-e2600224565c', tool_call_id='call_4mTVMhHDl0QemMmmHuBRhZTP'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'function': {'arguments': '{\"question\":\"Show 5 trials that tested drugs against the top 7 liver-related disorders\",\"top_k\":5}', 'name': 'mimicking'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 441, 'total_tokens': 475, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_7f6be3efb0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-db90e46b-c064-4c39-ac48-9b5d40f60958-0', tool_calls=[{'name': 'mimicking', 'args': {'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'top_k': 5}, 'id': 'call_NQky5Kfynd5inJQEd9k0WKfX', 'type': 'tool_call'}], usage_metadata={'input_tokens': 441, 'output_tokens': 34, 'total_tokens': 475, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", name='mimicking', id='754879b8-225b-4a3b-8cec-a690f679f044', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content=\"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", additional_kwargs={}, response_metadata={}, name='mimicking', id='4d5ed412-2709-4106-9c1e-ff4a8b53cc45', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), AIMessage(content='Here are five trials that tested drugs against liver-related disorders, specifically focusing on Fascioliasis and the drug Triclabendazole:\\n\\n| Trial ID | Title                                                                                                            | Disorder     | Drug             |\\n|----------|------------------------------------------------------------------------------------------------------------------|--------------|------------------|\\n| 20297    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran. | Fascioliasis | triclabendazole   |\\n| 20298    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile. | Fascioliasis | triclabendazole   |\\n| 20299    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba. | Fascioliasis | triclabendazole   |\\n| 20300    | Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia. | Fascioliasis | triclabendazole   |\\n| 20301    | Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke). | Fascioliasis | triclabendazole   |\\n\\nThese trials all focus on the treatment of Fascioliasis using Triclabendazole across various locations.', additional_kwargs={'question': 'Show 5 trials that tested drugs against the top 7 liver-related disorders', 'query': \"SELECT Trials.PostingID AS trial_id, Trials.StudyTitle AS StudyTitle, target_disease.name, drug_for_disorder.drug_name\\nFROM Trials,\\n(SELECT disorder_cui, name FROM Disorder\\nORDER BY array_distance(definitionEmbedding, embeddings('liver-related disorders')::FLOAT[1536])\\nLIMIT 7) target_disease,\\nGRAPH_TABLE(drug_graph MATCH (i:Drug)-[m:MAY_TREAT]->(c:Disorder)\\nCOLUMNS (i.drug_cui AS drug_cui, i.name AS drug_name, c.disorder_cui AS disorder_cui)) drug_for_disorder\\nWHERE target_disease.disorder_cui = drug_for_disorder.disorder_cui AND list_contains(Trials.drug_cui, drug_for_disorder.drug_cui)\\nLIMIT 5;\", 'execute_result': [[20297, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Iran.', 'Fascioliasis', 'triclabendazole'], [20298, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Chile.', 'Fascioliasis', 'triclabendazole'], [20299, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Cuba.', 'Fascioliasis', 'triclabendazole'], [20300, 'Evaluation of Triclabendazole (CGP 23030) in the treatment of chronic human infection with Fasciola hepatica (liver fluke) in Bolivia.', 'Fascioliasis', 'triclabendazole'], [20301, 'Dose finding trial with postprandial triclabendazole in Bolivian children infected with Fasciola hepatica (liver fluke).', 'Fascioliasis', 'triclabendazole']]}, response_metadata={}, id='dd184c63-e0ec-41aa-9398-8648ae918d83', tool_call_id='call_NQky5Kfynd5inJQEd9k0WKfX'), HumanMessage(content='The \"Three Small Guys\" pharmaceutical companies are Astellas, Novartis, and ViiV', additional_kwargs={}, response_metadata={}, id='168c56b2-77e8-4b14-b21b-af03ef8135c0'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1418, 'total_tokens': 1437, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-65d48a4a-01aa-4455-acaf-42508150fa42-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_BbnYMzW6NWuYXHItZSSTlNqY', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1418, 'output_tokens': 19, 'total_tokens': 1437, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='updated concept', name='memory', id='6cd4f9f8-8510-4314-b5a1-6d115e93ae7e', tool_call_id='call_BbnYMzW6NWuYXHItZSSTlNqY'), HumanMessage(content='We also define \"the Market leader\" company as GSK', additional_kwargs={}, response_metadata={}, id='722645df-bc28-4f5d-8a2b-dec008bc7363'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'function': {'arguments': '{\"action_type\":\"update_concept\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1464, 'total_tokens': 1483, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6951dbc0-47d3-42b7-9009-84fe6f6c7a5b-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'update_concept'}, 'id': 'call_6C8SUAwzy1H8bR2dkG6hrUnB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1464, 'output_tokens': 19, 'total_tokens': 1483, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='updated concept', name='memory', id='598bd5fe-57a7-4b40-a13b-ec9fb44fe684', tool_call_id='call_6C8SUAwzy1H8bR2dkG6hrUnB'), HumanMessage(content='Tabulate the amount of trials sponsored by \"the Three small guys\".', additional_kwargs={}, response_metadata={}, id='fbc12694-32e1-4e69-94c7-16d6448aa025', tool_choice='sql'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1512, 'total_tokens': 1531, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1280}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-91cdf93c-3fe6-460a-bcb0-faeaa1146b64-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_FixZDNScYgtmHjosgoJwOIyC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1512, 'output_tokens': 19, 'total_tokens': 1531, 'input_token_details': {'audio': 0, 'cache_read': 1280}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='49431405-61a8-4462-9339-4c0333e23171', tool_call_id='call_FixZDNScYgtmHjosgoJwOIyC'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_AldpqkdPBSnKknGTCVDWjS7c', 'function': {'arguments': '{\"question\":\"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN (\\'Astellas\\', \\'Novartis\\', \\'ViiV\\') GROUP BY Sponsor\",\"top_k\":50}', 'name': 'sql'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 48, 'prompt_tokens': 1017, 'total_tokens': 1065, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-88cb5860-7e1d-4f10-821c-aaca16ec7bce-0', tool_calls=[{'name': 'sql', 'args': {'question': \"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') GROUP BY Sponsor\", 'top_k': 50}, 'id': 'call_AldpqkdPBSnKknGTCVDWjS7c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1017, 'output_tokens': 48, 'total_tokens': 1065, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", name='sql', id='706718d3-c92f-4c59-b654-0b56d1718e8f', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'), HumanMessage(content=\"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='sql', id='652020e6-838a-42a7-aa08-6cfc6eabfa4f', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'), AIMessage(content='Here are the results formatted into sentences:\\n\\n- Astellas has conducted 101 trials.\\n- Novartis has conducted 239 trials.\\n- ViiV has conducted 76 trials.\\n\\nAlternatively, the results can be presented in a table format:\\n\\n| Sponsor   | TrialCount |\\n|-----------|------------|\\n| Astellas  | 101        |\\n| Novartis  | 239        |\\n| ViiV     | 76         |', additional_kwargs={'question': \"SELECT Sponsor, COUNT(*) as TrialCount FROM Trials WHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') GROUP BY Sponsor\", 'query': \"SELECT Sponsor, COUNT(*) AS TrialCount \\nFROM Trials \\nWHERE Sponsor IN ('Astellas', 'Novartis', 'ViiV') \\nGROUP BY Sponsor\\n LIMIT 50;\", 'execute_result': [['Astellas', 101], ['Novartis', 239], ['ViiV', 76]]}, response_metadata={}, id='004b9990-363b-4ee0-8dd0-f50e2cf6c177', tool_call_id='call_AldpqkdPBSnKknGTCVDWjS7c'), HumanMessage(content='Calculate the amount of trials sponsored by the market leader.', additional_kwargs={}, response_metadata={}, id='5f1c616b-8e49-4e3d-9c4e-7bbc3f874fd4', tool_choice='sql'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_XzJ41uh35e3DbUk1gtc6L9t1', 'function': {'arguments': '{\"action_type\":\"select_query_tool\"}', 'name': 'Choose_Direction'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 1790, 'total_tokens': 1809, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1408}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c03e4533-dea4-4242-bd34-8efe2afcebba-0', tool_calls=[{'name': 'Choose_Direction', 'args': {'action_type': 'select_query_tool'}, 'id': 'call_XzJ41uh35e3DbUk1gtc6L9t1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1790, 'output_tokens': 19, 'total_tokens': 1809, 'input_token_details': {'audio': 0, 'cache_read': 1408}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='', id='7e78f81f-4a83-43ee-9cea-586fb2993495', tool_call_id='call_XzJ41uh35e3DbUk1gtc6L9t1'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ERn85u25GzjIPLqhOXTWPAhz', 'function': {'arguments': '{\"question\":\"Calculate the amount of trials sponsored by GSK.\",\"top_k\":50}', 'name': 'sql'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 1090, 'total_tokens': 1116, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-aeaa305c-339f-4957-acbf-cb65424243d6-0', tool_calls=[{'name': 'sql', 'args': {'question': 'Calculate the amount of trials sponsored by GSK.', 'top_k': 50}, 'id': 'call_ERn85u25GzjIPLqhOXTWPAhz', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1090, 'output_tokens': 26, 'total_tokens': 1116, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content=\"SELECT COUNT(PostingID) AS trial_count \\nFROM Trials \\nWHERE LOWER(Sponsor) = LOWER('GSK')\\n LIMIT 50;\", name='sql', id='773f4dd9-0964-4695-b77a-8d9ef81c7881', tool_call_id='call_ERn85u25GzjIPLqhOXTWPAhz'), HumanMessage(content=\"SELECT COUNT(PostingID) AS trial_count \\nFROM Trials \\nWHERE LOWER(Sponsor) = LOWER('GSK')\\n LIMIT 50;\", additional_kwargs={}, response_metadata={}, name='sql', id='ca4bc251-c95a-4b5d-bd78-12bc0029200e', tool_call_id='call_ERn85u25GzjIPLqhOXTWPAhz'), AIMessage(content='The amount of trials sponsored by GSK is 1705. \\n\\nHere is the information formatted in a table:\\n\\n| Sponsor | Number of Trials |\\n|---------|------------------|\\n| GSK     | 1705             |', additional_kwargs={'question': 'Calculate the amount of trials sponsored by GSK.', 'query': \"SELECT COUNT(PostingID) AS trial_count \\nFROM Trials \\nWHERE LOWER(Sponsor) = LOWER('GSK')\\n LIMIT 50;\", 'execute_result': [[1705]]}, response_metadata={}, id='02b51180-9fa7-4681-9544-6263e70852f2', tool_call_id='call_ERn85u25GzjIPLqhOXTWPAhz'), HumanMessage(content='Thank you very much', additional_kwargs={}, response_metadata={}, id='59ec1303-8f3b-42d7-a3d2-e617f2b95cb0', tool_choice='automatic'), AIMessage(content=\"You're welcome! If you have any more questions or need further assistance, feel free to ask. Have a great day!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 1971, 'total_tokens': 1996, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1664}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_831e067d82', 'finish_reason': 'stop', 'logprobs': None}, id='run-3d70228f-8083-498b-acec-65957b6d3adb-0', usage_metadata={'input_tokens': 1971, 'output_tokens': 25, 'total_tokens': 1996, 'input_token_details': {'audio': 0, 'cache_read': 1664}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "len(message.tool_calls) =  0\n",
      "len: 36\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(\n",
    "    content=\"\"\"Thank you very much\"\"\", tool_choice=\"automatic\"\n",
    "    #content=\"\"\"Calculate the amount of trials sponsored by each of \"the Three small guys\".\"\"\", tool_choice=\"sql\"\n",
    ")\n",
    "\n",
    "for event in graph_definition.app.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    print (\"len:\", len(event[\"messages\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
